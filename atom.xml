<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr言的博客</title>
  
  <subtitle>记录点滴</subtitle>
  <link href="https://www.mryan.cool/atom.xml" rel="self"/>
  
  <link href="https://www.mryan.cool/"/>
  <updated>2021-10-14T17:01:56.082Z</updated>
  <id>https://www.mryan.cool/</id>
  
  <author>
    <name>严轶轩</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>python依赖树--pipdeptree</title>
    <link href="https://www.mryan.cool/2021/10/14/python%E4%BE%9D%E8%B5%96%E6%A0%91-pipdeptree/"/>
    <id>https://www.mryan.cool/2021/10/14/python%E4%BE%9D%E8%B5%96%E6%A0%91-pipdeptree/</id>
    <published>2021-10-14T08:55:10.000Z</published>
    <updated>2021-10-14T17:01:56.082Z</updated>
    
    <content type="html"><![CDATA[<p><strong>pipdeptree</strong>是一个命令行工具，用于以依赖树的形式显示已安装的python包。可以用来检测全局的库包或者虚拟环境的库包。</p><p><code>pip freeze</code>只能显示一个扁平的列表，只能显示直接依赖，而无法显示间接依赖，并且觉察三方库冲突的问题。</p><p><strong>pipdeptree</strong>可以显示间接依赖，同时发现其冲突</p><h1 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install pipdeptree</span><br></pre></td></tr></table></figure><h1 id="在虚拟环境中运行"><a class="markdownIt-Anchor" href="#在虚拟环境中运行"></a> 在虚拟环境中运行</h1><p>可以直接在虚拟环境中运行pipdeptree</p><p>也可以用–python选项来指定虚拟环境</p><h1 id="用法"><a class="markdownIt-Anchor" href="#用法"></a> 用法</h1><h2 id="显示包"><a class="markdownIt-Anchor" href="#显示包"></a> 显示包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree</span><br></pre></td></tr></table></figure><h2 id="显示特定的包"><a class="markdownIt-Anchor" href="#显示特定的包"></a> 显示特定的包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --packages xxx</span><br></pre></td></tr></table></figure><h2 id="排除特定的包"><a class="markdownIt-Anchor" href="#排除特定的包"></a> 排除特定的包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --exclude xxx</span><br></pre></td></tr></table></figure><h2 id="生成requirementtxt"><a class="markdownIt-Anchor" href="#生成requirementtxt"></a> 生成requirement.txt</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --warn silence | grep -E &#39;^\w+&#39;</span><br></pre></td></tr></table></figure><h2 id="生成json输出"><a class="markdownIt-Anchor" href="#生成json输出"></a> 生成json输出</h2><p>输出直接依赖</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --json</span><br></pre></td></tr></table></figure><p>输出间接依赖</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --json-tree</span><br></pre></td></tr></table></figure><h2 id="可视化调用图"><a class="markdownIt-Anchor" href="#可视化调用图"></a> 可视化调用图</h2><p>首先需要安装<a href="http://www.graphviz.org">GraphViz</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipdeptree --graph-output xxx &gt; dependencies.dot</span><br></pre></td></tr></table></figure><h2 id="usage"><a class="markdownIt-Anchor" href="#usage"></a> Usage</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usage: pipdeptree.py [-h] [-v] [-f] [--python PYTHON] [-a] [-l] [-u]</span><br><span class="line">                     [-w [&#123;silence,suppress,fail&#125;]] [-r] [-p PACKAGES]</span><br><span class="line">                     [-e PACKAGES] [-j] [--json-tree]</span><br><span class="line">                     [--graph-output OUTPUT_FORMAT]</span><br><span class="line"></span><br><span class="line">Dependency tree of the installed python packages</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  -v, --version         show program&#39;s version number and exit</span><br><span class="line">  -f, --freeze          Print names so as to write freeze files</span><br><span class="line">  --python PYTHON       Python to use to look for packages in it (default:</span><br><span class="line">                        where installed)</span><br><span class="line">  -a, --all             list all deps at top level</span><br><span class="line">  -l, --local-only      If in a virtualenv that has global access do not show</span><br><span class="line">                        globally installed packages</span><br><span class="line">  -u, --user-only       Only show installations in the user site dir</span><br><span class="line">  -w [&#123;silence,suppress,fail&#125;], --warn [&#123;silence,suppress,fail&#125;]</span><br><span class="line">                        Warning control. &quot;suppress&quot; will show warnings but</span><br><span class="line">                        return 0 whether or not they are present. &quot;silence&quot;</span><br><span class="line">                        will not show warnings at all and always return 0.</span><br><span class="line">                        &quot;fail&quot; will show warnings and return 1 if any are</span><br><span class="line">                        present. The default is &quot;suppress&quot;.</span><br><span class="line">  -r, --reverse         Shows the dependency tree in the reverse fashion ie.</span><br><span class="line">                        the sub-dependencies are listed with the list of</span><br><span class="line">                        packages that need them under them.</span><br><span class="line">  -p PACKAGES, --packages PACKAGES</span><br><span class="line">                        Comma separated list of select packages to show in the</span><br><span class="line">                        output. If set, --all will be ignored.</span><br><span class="line">  -e PACKAGES, --exclude PACKAGES</span><br><span class="line">                        Comma separated list of select packages to exclude</span><br><span class="line">                        from the output. If set, --all will be ignored.</span><br><span class="line">  -j, --json            Display dependency tree as json. This will yield &quot;raw&quot;</span><br><span class="line">                        output that may be used by external tools. This option</span><br><span class="line">                        overrides all other options.</span><br><span class="line">  --json-tree           Display dependency tree as json which is nested the</span><br><span class="line">                        same way as the plain text output printed by default.</span><br><span class="line">                        This option overrides all other options (except</span><br><span class="line">                        --json).</span><br><span class="line">  --graph-output OUTPUT_FORMAT</span><br><span class="line">                        Print a dependency graph in the specified output</span><br><span class="line">                        format. Available are all formats supported by</span><br><span class="line">                        GraphViz, e.g.: dot, jpeg, pdf, png, svg</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;pipdeptree&lt;/strong&gt;是一个命令行工具，用于以依赖树的形式显示已安装的python包。可以用来检测全局的库包或者虚拟环境的库包。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip freeze&lt;/code&gt;只能显示一个扁平的列表，只能显示直接依赖，而无法显示</summary>
      
    
    
    
    <category term="第三方库" scheme="https://www.mryan.cool/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"/>
    
    
    <category term="python" scheme="https://www.mryan.cool/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>In Search of an Understandable Consensus Algorithm(Extended Version)</title>
    <link href="https://www.mryan.cool/2021/09/02/In-Search-of-an-Understandable-Consensus-Algorithm-Extended-Version/"/>
    <id>https://www.mryan.cool/2021/09/02/In-Search-of-an-Understandable-Consensus-Algorithm-Extended-Version/</id>
    <published>2021-09-02T08:09:24.000Z</published>
    <updated>2021-09-05T16:29:17.168Z</updated>
    
    <content type="html"><![CDATA[<h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> abstract</h1><p>raft是一个管理分布日志的一致性算法，运行结果和Paxos一致，但是结构并不一样，因此Raft比Paxos更易懂，也为构建系统提供了更好的基础。为了更好理解，Raft将一致性的关键点分开，比如领导选取，日志备份，安全性。通过减少了状态数量加强了一致性的强度。</p><h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h1><p>Raft的目的是<strong>可理解性</strong>。因此将关键元素进行解偶。相关特性</p><ol><li>Strong leader：Raft提供了一个比别的算法更强劲的leader。比如日志条目仅仅从leader到其他的server，使得Raft更好管理备份日志</li><li>Leader elction：Raft用一个随机的定时器来选举leader。这仅仅在其他算法的心跳机制上添加少量机制即可</li><li>Membership changes：使用一个联合一致方法，使得在配置改变时，集群仍然可以工作</li></ol><p>文章结构：</p><ol><li>section2：复制状态机问题</li><li>section3：讨论优点和缺点</li><li>section4：理解性设计</li><li>Section5-8：表示Raft，评估Raft</li><li>Section10：讨论相关工作</li></ol><h1 id="复制状态机"><a class="markdownIt-Anchor" href="#复制状态机"></a> 复制状态机</h1><p>一致性算法通常出现在复制状态机中 。在这个算法中，一系列状态机可以计算相同状态的相同副本，即使有几个服务器宕机，也可以继续执行。</p><p>复制状态机通常通过复制日志来实现，如图</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/3tBFjF.png" alt="" /></p><p>每个server存储一系列命令，其状态机按序执行命令。因为每个日志的命令都相同，因此每个状态机按照相同的循序执行命令。</p><p>一致性算法需要持久化备份日志。</p><p>一致性模块从client接受命令，然后添加到日志中。一致性模块会和其他server的一致性模块沟通，确保每个日志 最终一致，即使有一些server失败。</p><p>一致性模块有如下特点</p><ol><li>保证安全性，永远不会返回错误的结果</li><li>只要大多数服务器都是可操作的，并且可以与其他服务器和客户端通信，它们都是完全可用的</li><li>不依靠定时来保证一致</li><li>在一般情况下，只要集群的大多数成员响应了一轮远程过程调用，命令就可以完成;少数速度较慢的服务器不需要影响整个系统的性能</li></ol><h1 id="paxos的缺点"><a class="markdownIt-Anchor" href="#paxos的缺点"></a> Paxos的缺点</h1><p>Paxos最开始定义了协议，改协议能够就单个决策达成协议，我们称之为单一法令Paxos。</p><p>后来结合了多个实例，可以完成了一系列决策，比如日志。paxos保证了安全性和可用性，并且支持集群中成员的改变，其正确性已经在多个案例被证实</p><p>但是Paxos有两个很大的缺点：</p><ol><li>难以理解，不透明性<ol><li>来源于单一法令paxos的基础。</li></ol></li><li>没有为搭建系统系统良好的基础<ol><li>没有广泛认可的算法</li><li>理论和现实相差太远</li></ol></li></ol><h1 id="理解性设计"><a class="markdownIt-Anchor" href="#理解性设计"></a> 理解性设计</h1><p><strong>目标：</strong></p><ol><li>为系统搭建提供完整的，有实际意义的基础</li><li>必须安全</li><li>理解性<ol><li>将leader选举，日志复制，安全，成员改变进行解偶</li><li>减少状态空间，从而使得系统更全面和 减少其确定性，特别是，Raft不允许日志和其他日志不相同。</li><li>通过随机方法来简化leader选举</li></ol></li></ol><h1 id="raft一致性算法"><a class="markdownIt-Anchor" href="#raft一致性算法"></a> Raft一致性算法</h1><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/EyoLAi.png" alt="" /></p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/UucJha.png" alt="" /></p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/ijW7dY.png" alt="" /></p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/8mzGyt.png" alt="" /></p><p>Raft首先选举出一个leader，由leader来全权负责日志的复制。leader接收来自client的日志条目，在其他的server复制，并且告诉server什么时候让状态机执行这些命令日志条目是安全的。比如，leader可以决定在哪里放置日志条目，并且数据流仅仅从leader到其他的server，当leader失败或者和其他的server断开连接，则重新选举一个leader</p><p>根据leader的功能，我们可以将一致性问题分解成三个独立的子问题：</p><ol><li>leader选举：当leader失败时，一个新的leader被选举出来</li><li>日志复制：leader必须接受来自client的日志条目，并且复制到集群中，迫使其他日志和自己日志一致</li><li>安全性：</li></ol><p><strong>笔记：</strong></p><p><strong>state：</strong></p><ol><li>所有的server<ol><li>current term：用来记录该节点的当前的term</li><li>voteFor：投票给那个candidate</li><li>log[]：是log的数组，用来继续日志条目<ol><li>日志条目：<ol><li>term：该命令在那个term被创建</li><li>commang：该条目需要执行的命令</li></ol></li></ol></li><li>commit index：已经提交的log index的最大值。</li><li>lastApplied：执行的日志条目的index最大值。之所以要分开，是因为commit和apply不是同时进行，先commit再apply，因此需要记录两者执行的进度</li></ol></li><li>仅仅对leader<ol><li>nextindex[]：对每个server下一个需要发送的条目的index。因为每个server接受的进度不一样，需要发送的日志条目也不一样</li><li>matchindex[]：已经在server复制了的最大条目index。如果server已经复制，就不再需要发送条目了</li></ol></li></ol><p><strong>AppendEntries RPC：</strong></p><ol><li></li></ol><h2 id="raft基础"><a class="markdownIt-Anchor" href="#raft基础"></a> Raft基础</h2><p>一个集群包含几个server，一般是5个，允许系统出现2个机器同时失败。在任何一个时刻，每个server必定处于leader，follower，candidate三个状态之中。</p><ol><li>follower：在正常情况下，只有一个leader，其余的server都是follower。follower是被动的，他们不发出任何请求，仅仅只是想赢来自leader和candidate的请求。</li><li>leader：处理所有的client请求（如果client与follower接触，follower直接重定向给leader）</li><li>candidate：用来选举出一个新的leader</li></ol><p>如图5，Raft将时期分割成任意长度的任期(term)，term用连续的整数编号。每个term以一个election开始，该阶段是一个或若干个candidate竞争成为leader。如果candidate成为leader，则会在接下来的时间中担任leader 。在一些情况下，选举会导致投票分裂，这种情况下没有leader，term会结束，一个新的term重新开始，同时继续开始选举，同时Raft保证一个 term中最多只有一个leader</p><p>在Raft中，term被看作一个逻辑时钟，允许server去检测过期的信息，比如过期的leader。每个server都会存储一个current term数字，它会随着时间单调增加。current term会在server沟通时交换。如果一个server的current term小于其他server的current term，则会更新他的current term。如果一个candidate和leader发现他的term过期了，会立即返回成follower状态。如果一个server接收到一个过期的term数，他会丢弃该请求。</p><h2 id="leader选举"><a class="markdownIt-Anchor" href="#leader选举"></a> Leader选举</h2><p>Raft使用心跳检测来触发leader选举。当server启动时，他们作为follower。只要server收到candidate或者leader的RPC，server仍然作为follower。</p><p>Leader会定期发送心跳检测(不携带日志条目的AppendEnteies RPC)以维持leader的任期。如果follower在一定时间内没有收到消息，咋选举超时(eletion timeout)，则会假设没有leader，并且重新选举一个新的leader。</p><p>选举初期，follower会增加其current term，并且过渡到candidate。他会投票给自己，并且并发发送RequestVote RPC给集群中的每个server，candidate会一直保持其candidate状态，直到：</p><ol><li>赢得选举<ol><li>如果一个cndidate在同一term内从整个集群中的大多数服务器获得选票，那么他就赢得了选举</li><li>每个server在给定的term按照先到先得的规则投票给最多一个candidate</li><li>一旦candidate成为leader，就会发送心跳消息给所有server，建立其权威，防止新的选举。</li></ol></li><li>其他的server赢得选举<ol><li>在等待投票期间，candidate可能会收到其他想成为leader的candidate的AppendEntries RPC。如果发现leader的current term大于等于自己的current term，则承认leader的权威，并且是自己回到follower状态。如果leader的term小于自己的current term，candidate则拒绝该RPC，继续以candidate的状态继续。</li></ol></li><li>一段时间内无人获得选举<ol><li>无人选举leader，每个candidate会time out，通过增加其current term来重新进行选举，然而，如果不采取额外的措施，无人赢得选举可能永远发生。</li><li>Raft使用随机选举超时来保证该情况不用永远发生。election timeout一般被随机选择为150ms-300ms之间。如此划分，会导致大多数情况只有一个server会发生election timeout。每个candidate在选举开始时，随机自己的election timeout，并且在election timeout结束后开始下一轮选举。</li></ol></li></ol><h2 id="日志复制"><a class="markdownIt-Anchor" href="#日志复制"></a> 日志复制</h2><p>一旦选举出leader，就需要处理client的请求。每个client请求包含一个需要执行的命令。leader将命令添加到日志中作为一个新的条目，然后并发发送一个APpendEntries RPC给每个server来复制日志。当条目被成功复制，leader会运行这些条目，然后返回结果给client。如果follower崩溃或者运行缓慢，或者网络丢包，leader会重新无限尝试发送AppendEntries RPC(即使leader已经响应client)，直到所有的follower最终一致。</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/Oiuws9.png" alt="" /></p><p>如图6，每个日志条目存储命令和leader接受该命令的current term。term是用来发现日志之间的不一致性的，从而保证图3。每个日志条目都有一个index</p><p>由leader来决定什么时候状态机可以运行日志条目，这样的条目成为committed。Raft保证commited条目是持久的，并且最终会被所有可用的状态机执行。一旦一个日志条目在多个server上复制，就会被设置为committed。</p><p>leader跟踪他所知道的committed条目的最大索引，并且在存储未来的AppendEntried RPC中，以至于其他的server最终可用发现他，一旦follower知道一个日志条目给提交了，他就会在状态机中运行条目。</p><p>Raft维持以下特征，从而保证图3的Log Matching：</p><ol><li>如果在不同日志的两个条目有相同的index和term，他们一定存储一样的command</li><li>如果不同日志的两个条目有相同的index和term，则上述条目都是一样的</li></ol><p>第一个特点表示对于一个leader，在给定日志index和term的情况下，至多创建一个条目，并且日志条目永远不会改变他在日志中的位置；</p><p>第二个特点由AppendEntries的简单一致性检查保证。当发送APpendEntries RPC时，leader包含新条目处理之前的日志条目的index和term，如果follower没有在他的日志中没有发现相同index和term的条目，则会拒绝新的条目。该一致性检查有一个归纳步骤：</p><ol><li>日志的空状态满足Log Matching Property</li><li>一致性检查保证Log Matching Property在日志扩展的任何时候都满足</li><li>当APpendEntries成功结束时，leader知道follower的日志和自己的日志一致</li></ol><p>在正常操作下，leader和follower的日志保持一致，因此APpendEntries一致性检查不会失败，但是当leader崩溃时，可能导致日志不一致，老的leader可能没有完全复制日志中的所有条目。这些不一致性会在leader和follower崩溃中加剧。</p><p>在Raft中，leader强迫follower复制自己的日志来保持一致。这表示在follower日志中冲突的条目会被leader日志中的条目覆写。</p><p>为了 保证follower日志和自己的日志的一致性，leader 必须找到leader日志和follower日志中最新的条目，然后删除follower该条目之后的条目，然后leader发送最新节点之后的条目给follower。</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/mSTZDE.png" alt="" /></p><p>leader为每个follower维持一个nextIndex[]，下一个日志条目的index需要发给follower。当leader第一次成为leader时，会初始化所有的nextindex为其最后一个日志的索引。比如图7，nextindex为11(index从1开始)，如果follower的日志和leader的日志不一致，AppendEntries一致性检查会在下一次的AppendEntries RPC中失败。在被拒绝后，leader减少nextINdex的值，并且重新发送AppendEntries RPC，最终nextindex会达到一个leader和follower日志都满足的一个点。当达到该点时候，AppendEntries会成功，将删掉follower日志该点之后的条目，并且追加leader该点之后的条目。一旦AppendEntries成功，follower的日志会和leder的日志一致，在term的剩下时间内，会维持这种状态。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果需要，该协议可以进行优化来减少AppendEntried失败的次数，比如，当拒绝AppendEntries请求时，follower可以存储冲突条目的term和存储该term的第一个idnex，有了这个信息，在leader可以直接跳过该term的所有项，这样的话，对于一个冲突term只需要一个AppendEntries RPC，而不是一个index就需要一个AppendEntries RPC。</span><br></pre></td></tr></table></figure><p>通过该方式，leader在当上leader时不需要做出特别操作来完成日志一致，仅仅是正常操作，日志会因为AppendEntries一致性检查的失败而收敛，leader永远不需要覆写或者删除自己的条目，保证了图三的Leader Append-Only property。</p><h2 id="安全性"><a class="markdownIt-Anchor" href="#安全性"></a> 安全性</h2><p>上述描述了Raft如何leader选举和日志条目。然后，目前为止还不能保证每个状态机按照相同的顺序执行相同的命令。</p><h3 id="选举限制"><a class="markdownIt-Anchor" href="#选举限制"></a> 选举限制</h3><p>在任何基于leader的一致性算法中，leader必须最终存储所有committed的日志条目。</p><p>Raft用一种方式来保证每个leader在当选时刻会有之前term所有committed的条目，不需要发送这些条目给leader。这意味着日志条目仅仅沿着一个方向，即leader到follower，leader永远不会覆写已经存在的条目。</p><p>Raft用投票处理来阻止candidate赢得选举，除非他的日志包含所有committed条目。一个candidate必须和集群中的大多数server来通信，从而赢得选举，那就意味着哪些server中至少有一个存储每个committed条目。如果candidate的日志和其他日志至少是一样最新的，他将存储所有commited条目。The RequestVote RPC实现该限制，RPC包含candidate日志信息，投票者如果发现他自己的日志比candidate的日志更新，则不会投票。</p><p>Raft通过比较最后一个条目的index和term来判断那个最新。如果日志最后一个条目有不同term，有更后term的日志更新。如果日志最后的条目都相同，日志更长的更新。</p><h1 id="集群成员变更"><a class="markdownIt-Anchor" href="#集群成员变更"></a> 集群成员变更</h1><p>目前集群的成员配置都是固定的。在现实中，可能会改变配置，比如可能更换server或者切换备份等级，因此Raft需要能够自动改变配置。</p><p>为了确保配置变更机制的安全，在过渡期间必须没有可能出现两位领导人同时当选的情况。不幸的事，任何server配置变更都是不安全的，他不可能一次性自动切换所有的server，所以集群可能会分成两个服务器组。如图</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/4ELVGg.png" alt="" /></p><p>为了保证安全性，配置变更必须使用两阶段策略。比如，有些系统会让旧配置失效，无法处理client请求，然后第二阶段使用新配置。</p><p>在Raft集群中，第一个切换我们成为joint consensus，有点joint consensus成功，系统会进入新的配置。joint consensus结合了新老两种配置。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;abstract&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#abstract&quot;&gt;&lt;/a&gt; abstract&lt;/h1&gt;
&lt;p&gt;raft是一个管理分布日志的一致性算法，运行结果和Paxos一致，但是结构并不一样，因此Raft比Paxos</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="文件系统" scheme="https://www.mryan.cool/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>The Google File System</title>
    <link href="https://www.mryan.cool/2021/08/18/The-Google-File-System/"/>
    <id>https://www.mryan.cool/2021/08/18/The-Google-File-System/</id>
    <published>2021-08-18T00:26:11.000Z</published>
    <updated>2021-08-24T10:15:15.045Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本文是对谷歌论文：The Google File System的笔记</strong></p><p><strong>作者：Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung Google∗</strong></p><p><strong>URL：<a href="http://nil.csail.mit.edu/6.824/2020/papers/gfs.pdf">http://nil.csail.mit.edu/6.824/2020/papers/gfs.pdf</a></strong></p><h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1><p>谷歌文件系统是一个可扩展的分布式文件系统，用于大型分布式数据密集型系统。在商业硬件的基础上，提供了容错机制，并且对大量客户端提供了较高的综合性能</p><h1 id="关键词"><a class="markdownIt-Anchor" href="#关键词"></a> 关键词</h1><p>容错机制，可扩展，数据存储，集群存储</p><h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1><ol><li>部件失效是正常而不是异常。文件系统由成千上百商业机器组成，被大量客户访问。这些部件的数量和质量几乎保证了某些部件在任何给定时间都不能正常工作，而某些部件则无法从当前的故障中恢复过来。</li><li>按照标准，文件是巨大的。GB文件是常见的。每个文件包含了许多应用对象，比如web文件。当定期处理快速增长，并且包含许多对象的TB文件时，按照处理KB文件的方式处理它们很不明智，尽管文件系统可以这么做。因此，设计思想和参数设置比如I/O操作和块大小必须重新考虑</li><li>大多数文件是以追加的形式改变，而不是直接重写。在文件的随机写操作实际上是不存在的。一旦写入，文件只能读取，并且只能按顺序。按照这种特性，追加成为性能优化和原子性保证的重点，在客户中缓存失去了吸引力</li><li>共同设计应用程序和文件系统API可以提高我们的灵活性，从而使整个系统受益。比如放宽了GFS的一致性模型，可以简化我们的设计，但是不会对应用造成困难。</li></ol><h1 id="设计梗概"><a class="markdownIt-Anchor" href="#设计梗概"></a> 设计梗概</h1><h2 id="假设"><a class="markdownIt-Anchor" href="#假设"></a> 假设</h2><ol><li>系统运行在许多商业部件上，这些部件容易异常。系统必须持续监控自己，在日常工作失败时，快速发现，容忍，恢复部件</li><li>系统存储许多大文件。假设有几百万个文件，通常在100MB甚至更大。GB级别的文件是很常见的，并且需要有效管理。小文件也需要支持，但我们不用特殊优化他们</li><li>工作量主要有两种读构成。大的流读和小的随机读。在大的流读中，单个操作通常读数百KB，甚至超过1MB。来自同一客户端的操作通常读一个文件的连续部分。小的随机读通常在任意文件处读几KB。性能敏感的应用程序经常对小的读取进行批处理和排序，以便在文件中稳步推进，而不是来回切换。</li><li>工作量还有大量的连续写，在文件中追加数据。一般操作大小和读差不多。一旦写入，文件便无法修改。在任意处的小规模的写也支持，但不用特殊优化</li><li>系统必须有效地为并发地追加到同一个文件的多个客户端实现定义良好的语义。我们的文件经常被用作生产者-消费者队列或多路合并。大量生产者运行在同一台机器，并发追加到文件。具有最小同步开销的原子性是必不可少的。文件可能稍后被读取，或者使用者可能同时读取文件。</li><li>高持续宽带比低延迟更重要。我们的大多数目标应用程序都注重以高速率批量处理数据，而很少有应用程序对单独的读或写有严格的响应时间要求</li></ol><h2 id="接口"><a class="markdownIt-Anchor" href="#接口"></a> 接口</h2><p>GFS提供基本操作，create , delete , open ,close ,read , write</p><p>也提供快照和追加记录。快照用较低的成本创建一个文件或目录树的副本。追加记录允许多个客户并发向同一个文件追加数据，同时保证每个用户追加操作的原子性。系统适用于实现多路合并结果和生产者-消费者队列，许多客户端可以在没有附加锁的情况下同时追加数据。</p><h2 id="架构"><a class="markdownIt-Anchor" href="#架构"></a> 架构</h2><p>GFS集群由一个master和多个chunkserver构成，并且被多个client访问。</p><p>![](/Users/yixuanyan/Library/Application Support/typora-user-images/image-20210818113543838.png)</p><p>文件被分成固定的chunk。每个chunk在被创建时被一个全局独有并且不可变的64比特chunk handle所标记。chunkserver在本地磁盘存储chunk，就像Linux 文件，根据chunk handle和比特范围来读或者写。为了稳可靠性，每个chunk在多个chunserver复制，默认是三份，尽管用户可以为了文件命名空间的不同区域指定不同的复制层次。</p><p>master维护所有文件系统元数据，包括命名空间，访问信息，文件到chunk的映射，chunk的当前位置。同时还控制系统范围的活动，比如chunk租贷管理，孤儿chunk的垃圾回收，chunkserver的chunk迁移。master定期通过心跳信息和每个chunkserver沟通，并且给予指令和收集其状态。</p><p>连接到每个应用的GFS client代码都实现了文件系统的API，并且可以和master和chunkserver沟通来代表应用进行读，写数据。client和master交互，进行元数据的操作，但是所有和传输数据相关的操作直接于chunkserver进行。</p><p>client和chunkserver都不需要缓存文件数据。客户机缓存几乎没有什么好处，因为大多数应用程序都要处理巨大的文件，或者工作集太大而无法缓存。没有缓存一致性问题，简化了客户端和整个系统。chunkserver也不需要，因为chunk存储在本地文件，所以Linux的缓冲区缓存已经将频繁访问的数据保存在内存中了。</p><h2 id="单一master"><a class="markdownIt-Anchor" href="#单一master"></a> 单一master</h2><p>单一master可以通过全局变量来chunk的转移和复制决策。但是必须减少他对读写的影响，否则可能造成读写的瓶颈（因为master只有一个）。client不与master进行读写操作，相反，client向master询问需要与哪个chunserver交互。缓存这些信息，然后在接下来的操作中直接和chunkserver交互。（<strong>有没有一点像DMA？</strong>）</p><p><strong>读操作：</strong></p><ol><li>client将应用需要的文件名和偏移量转换成文件的chunk索引</li><li>client给master发送请求，请求包含文件名字和chunk索引</li><li>master返回对应的chunk handle和副本所在的位置</li><li>client缓存该信息，以文件名和chunk索引作为key</li><li>client发送请求到副本中的一个（大多数是最近的一个）。该请求表示了chunk handle和chunk的一个比特范围。随后的信息，不需要client和master交互，除非缓存信息过期或者文件重新打开。</li><li>PS：client也可以在向master的请求中访问几个chunk，这样master可以提供多个chunk的信息，这样在之后几个chunk的访问中，client不需要请求master</li></ol><h2 id="chunk大小"><a class="markdownIt-Anchor" href="#chunk大小"></a> chunk大小</h2><p>一般选择64MB，比传统的文件系统的block尺寸更大。每个chunk副本被存储为chunk server上的一个普通Linux文件，并且只在需要时进行扩展。 惰性空间分配避免了由于内部碎片而浪费空间，这可能是针对如此大的块大小的最大反对意见。</p><p><strong>大chunk的优点：</strong></p><ol><li>减少了client和master交互的次数。因为在同一个chunk的读写只需要一次请求。因为应用通常是在大文件的顺序读或写，因此这种减少极其重要。即使是小的随机读，client也可以轻松缓存所有的chunk位置信息</li><li>对于一个chunk，client可以做的操作更多，可以通过保持一个和chunkserver的TCP唱连接来减少网络负载。</li><li>减少了存储在master的元数据大小，这样可以使我们把元数据保存在内存中。（<strong>chunk越大，chunk数量越少，元数据个数越少</strong>）</li></ol><p><strong>大chunk的缺点：</strong></p><ol><li>一个小文件可能由很少的chunk构成，可能只有一个。chunkserver存储这些chunk，可能成为多个client访问的热点。在实践中，热点并不是主要问题，因为我们的应用程序大多是顺序读取大的多块文件。  <strong>（chunk越大，一个文件所需要的chunk数量越少，更容易成为热点）（其实我感觉就算是热点，也可以通过访问其副本的方式解决吧）</strong></li><li>谷歌将GFS用在批队列系统时，出现了热点问题，解决方式是加大热点的复制因子，增加其副本，错开client的访问时间。一个潜在的解决方案是，可以让client去访问别的client的chunk</li></ol><h2 id="元数据"><a class="markdownIt-Anchor" href="#元数据"></a> 元数据</h2><p><strong>master主要存储三种元数据：</strong></p><ol><li>文件和chunk命名空间</li><li>文件到chunk的映射</li><li>每个chunk的副本的位置</li></ol><p>第一个和第二个类型业户通过改变存储在master本地磁盘和副本的operation log来保护持久化。</p><p>master不会持久存储chunk位置信息。当master启动或者chunkserver加入集群中，master会询问每个chunkserver关于chunk的信息</p><h3 id="内存中的数据结构"><a class="markdownIt-Anchor" href="#内存中的数据结构"></a> 内存中的数据结构</h3><p>因为一些元数据存储在内存，master的操作很快。同时，对于master更加轻松和有效率在后台去检查整个状态。定期检查用来chunk垃圾回收，当chunkserver的再复制，chunk的迁移去均衡chunkserver的负载和磁盘空间。</p><p>这种只使用内存的方法的一个潜在问题是，chunk的数量以及整个系统的容量都受到master所拥有的内存的限制。在实践中并不是一个严重的限制。master为每个64MB的chunk维持一个不到64bite的状态。大多数chunk都是满的，因为大多数文件包含许多块，只有最后一个hunk可能部分被填满。同样地，文件名称空间数据通常需要每个文件少于64字节，因为它使用前缀压缩来存储文件名。</p><p>如果有必要支持更大的文件系统，那么向master添加额外内存的成本与将元数据存储在内存中所获得的简单性、可靠性、性能和灵活性相比是很小的代价。</p><h3 id="chunk位置"><a class="markdownIt-Anchor" href="#chunk位置"></a> chunk位置</h3><p>对于一个chunk，存储其副本的chunkserver的信息不会持久存储在master中。master仅仅在启动时，轮训访问chunkserver来获取相关信息。因为master通过心跳信息来控制所有chunk的位置和监控chunkserver状态，所以master可以保持最新状态。</p><p>之所以不用持久存储，是因为chunkserver的chunk可能会消失。因此持久存储没有意义</p><h3 id="operation-log"><a class="markdownIt-Anchor" href="#operation-log"></a> operation log</h3><p>operation log包含改变重要元数据的历史记录，对GFS十分关键。不仅仅是因为他是元数据的唯一持久化存储，并且他可以作为逻辑时间线来定义并发操作的顺序。</p><p>文件，chunk和他们的版本号都是独一无二的，不变的，他们都由他们被创建的逻辑时间定义</p><p>operation log很重要，我们必须可靠存储它，直到元数据更改被持久化之前，对client不可见。否则，即使chunk存在，我们也会失去整个文件系统和最新的client操作。因此，我们将其复制在另一个遥远的机器上，仅在本地和远处机器将相应的operation log写到磁盘后，再相应client的操作。master在刷新之前将多个log一起处理，从而减少了刷新和拷贝对整个系统吞吐量的影响。</p><p>master通过重演operation log来恢复文件系统状态。为了最小化启动时间，我们必须保持log最小。无论何时，当opetaion log的大小超过一定大小，master对其状态设置检查点，因此master可以通过从磁盘加载最近的检查点，仅仅重演在检查点之后的一部分operaton log的一系列操作来恢复状态。检查点是一种紧凑的类似b树的形式，可以直接映射到内存中，并用于名称空间查找，而不需要额外的解析，大大加快了恢复的速度和提高了可用性。</p><p>创建检查点需要耗费时间，为了不延迟即将要来的操作，master在另一个进程切换到一个新的log，并且创建一个新的检查点，新的检查点包括切换之前的所有信息。对于 一个百万机器的集群，需要花费一分钟。完成后，会写入本地和远处的磁盘</p><p>重新恢复仅仅需要最近的检查点和其之后的log文件。更好的检查点和log文件可以自由删除，但也可以保存一些以免别的意外。检查点期间的失败不会影响正确性，因为恢复代码会检测并跳过不完整的检查点</p><h2 id="一致性模型"><a class="markdownIt-Anchor" href="#一致性模型"></a> 一致性模型</h2><p>GFS是一个弱一致性模型，可以很好支持我们分布式应用，同时实现更好简单和有效率。我们会讨论GFS的保证和他们对应用意味着什么。我们也强调GFS如何维持这些保证。</p><h3 id="gfs的保证"><a class="markdownIt-Anchor" href="#gfs的保证"></a> GFS的保证</h3><p>文件命名空间的改变（比如文件的创建）是原子的。他们完全由master处理。命名空间锁保证了原子性和正确性，master的operation log定义了这些操作的全局顺序。</p><p>在数据更改后，文件区域的状态取决了更改的种类，是否成功，是否有并发改变。如下图</p><p>![](/Users/yixuanyan/Library/Application Support/typora-user-images/image-20210818202807439.png)</p><p>consistent：不管client从那个副本读，都是相通的</p><p>defined：他是consistent的，并且client会知道改变了什么。当一个改变成功，且没有收到并发写的影响，该区域就是defined，所有的client都会看到改变写了什么。</p><p>undefined but consistent：client看到的数据相同，但是不会看到条目中写了什么。当多个改变成功，不同于defined是他是多个改变，defined是一个改变。</p><p>inconsistent：不同的client在不同的时间看到不同的数据。是一个失败的改变导致。</p><p><strong>数据的更改主要是写和追加</strong></p><p>写是在应用指定文件的偏移量上写入数据。追加是在文件末尾至少原子性写入一次数据。</p><p>在一系列成功的改变后，被改变的文件保证是defined，并且包含文件最后一次更改的数据。步骤如下：</p><ol><li>以相同的顺序对chunk所在的副本进行改变</li><li>用chunk版本号去发现所有的陈旧的副本，因为这些chunkserver可能会因为宕机导致更改丢失</li></ol><p>陈旧的副本不会再涉及到更改，或者给询问master的client以位置信息。他们是最早回收的垃圾</p><p>因为client缓存chunk的位置，他们可以从陈旧的副本中读取如果相关信息没来得及刷新。这中情况会受到缓存超时和下一次打开文件的限制，这些会导致缓存清楚该文件所有的相关信息。此外，大多数文件是追加，这时，陈旧的副本返回的不是过时数据，而是不完整的数据。当一个读条目请求master时，会立即得到当前chunk的位置</p><p>在改变成功后，部件失败导致数据损坏的情况同样可能发生。GFS通过在master和所有的chunkserver握手来发现失败的chunkserver，并且通过校验和检查是否数据损坏。一旦问题发生，数据会尽快从好的副本中重新存储。一个chunk只有在GFS得以反应之前，所有的副本chunk都丢失，该chunk的丢失才不可逆。即使这样，他也只是不可用，而不是损坏。应用接收到的错误是error而不是损坏数据。</p><h3 id="应用的影响"><a class="markdownIt-Anchor" href="#应用的影响"></a> 应用的影响</h3><h1 id="系统交互"><a class="markdownIt-Anchor" href="#系统交互"></a> 系统交互</h1><p>我们要使master在操作中花费的成本最小，在此背景下，来讨论client，chunkserver，master如何交互来完成数据改变，原子记录追加，快照。</p><h2 id="租贷和mutation命令"><a class="markdownIt-Anchor" href="#租贷和mutation命令"></a> 租贷和mutation命令</h2><p>上文都是将mutation翻译成改变，但是感觉不是很符合原文的意思，于是还是不翻译mutation了</p><p>mutation是改变chunk元数据的内容，比如写数据或者追加操作。每个mutation都在chunk的所有副本上进行。我们使用租贷leash来维持所有副本间的一致性mutation顺序。</p><p>master将一个chunk租给副本中的一个，我们称之为primary。primary为chunk的mutation选择一个序列顺序。所有的副本在进行mutation时，按照这个顺序，</p><p>租贷机制是为了减少master的管理负载。租贷最初是60秒超时。primary可以无限地向master请求或者接受扩展。</p><p>过程如下图</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/WH2Zfh.png" alt="" /></p><ol><li>client询问master哪个chunkserver有当前chunk的租贷，并且当前chunk的其他副本。如果没有租贷，master会命名给一个副本。    <strong>ps：client向master询问primary和secondary</strong></li><li>master返回primart的标识符和其他secondary的位置。client缓存这些信息。client不需要在请求master，知道发现primary不可达，或者primary不再是primary。</li><li>client让数据发送到所有的副本。每个副本将数据存储到一个LRU缓冲区，直到数据被使用或者老化。通过将数据流和控制流解偶，可以提高网络拓扑，无论那个chunkserver是primary。</li><li>一旦所有的副本承认接收到了数据，client发送一个写请求给primary。该请求包括了之前发送到所有数据的标识。primary分配给这些标识符一个序列（这些标识符可能来自于多个client），这样保持了必要的串行。然后在本地上以这些序列来进行mutation</li><li>primary发送写请求给所有secondary副本。每个secondary使用和master分配的mutation序列。</li><li>secondary会回复primary他们完成所有操作</li><li>primary回复client。在任何副本发生的error都会报告给client。在有error的情况下，写操作在primary和任意部分secondary成功完成。（如果在primary操作出现error，咋不会给mutation分配序列同时发送给secondary）。如果出现失败，则client会选择重试，按照step3-step7.</li></ol><p>如果来自应用的写太大，超过了chunk的大小，GFSclient会把它切割成多个写操作。</p><h1 id="master的操作"><a class="markdownIt-Anchor" href="#master的操作"></a> master的操作</h1><p>master执行所有命名空间的操作。同时通过系统管理chunk的副本，做出放置决策，创建新的chunk和副本，协调各种系统工作区保证块的完全复制，平衡chunkserver的负载，回收没使用的存储</p><h2 id="命名空间管理和锁"><a class="markdownIt-Anchor" href="#命名空间管理和锁"></a> 命名空间管理和锁</h2><h2 id="副本置换"><a class="markdownIt-Anchor" href="#副本置换"></a> 副本置换</h2><p><strong>两个目的</strong></p><ol><li>最大化数据可靠性和可用性</li><li>最大化网络宽带的利用</li></ol><h2 id="复制再拷贝再平衡"><a class="markdownIt-Anchor" href="#复制再拷贝再平衡"></a> 复制，再拷贝，再平衡</h2><p><strong>chunk副本的创建有三种方式：</strong></p><ol><li>chunk创建</li><li>chunk再拷贝</li><li>chunk再平衡</li></ol><p>创建chunk时，需要考虑几点因素</p><ol><li>希望创建的chunkserver的空间利用率在平均值一下</li><li>希望限制一个chunkserver再一段时间内创建chunk的次数</li><li>希望将chunk副本分布在多个rack上</li></ol><p><strong>再复制</strong>：当chunk副本的数量小于用户目标时</p><ol><li>chunkserver不可用</li><li>chunkserver的磁盘坏了</li><li>用户的复制需求增加</li></ol><p><strong>再平衡：</strong></p><ol><li>平衡磁盘利用率</li><li>限制单一chunkserver的复制次数</li><li>平衡rack的副本</li></ol><h2 id="垃圾回收"><a class="markdownIt-Anchor" href="#垃圾回收"></a> 垃圾回收</h2><p>当文件被删除时，并不直接通知其副本，而是在垃圾回收的时候通知。</p><h3 id="机制"><a class="markdownIt-Anchor" href="#机制"></a> 机制</h3><p>当文件删除时，master记录delete命令，但是并不通知其副本，文件被命名为一个隐藏名字，其中包括了删除时间戳。当master定期检查文件系统命名空间时，会移除超过三天的隐藏名字（其中天数可以配置）。在此期间，文件还是可以根据这个新名字来读，如果想不删除，将名字改回正常即可。当文件从命名空间删除，他的元数据也删除。</p><p>在遍历chunk命名空间时，master也会标记孤儿chunk，并且抹去这些chunk的元数据。</p><p>在chunkserver和master的心跳信息中，chunkserver汇报他拥有的chunk，master回复那些不再存储元数据的chunk标记，这时候，chunkserver可以自由删除这些chunk的副本。</p><p><strong>该机制的优点：</strong></p><ol><li>在大型分布式系统中简单可靠</li><li>将多个命令合并成一个定期的命名空间的遍历和chunkserver的握手</li><li>延迟删除可以提供了网络安全，放置不可逆的删除</li></ol><p><strong>缺点：</strong></p><ol><li>当存储空间比较少的时候，延迟延迟会影响用户的使用，用户的重复创建，删除可能不能很好的复用空间。</li><li>解决方法，可以让用户标记不同的复制策略，比如用户可以标记一些目录的chunk不需要副本，这样删除文件可以直接删除，并且不可逆</li></ol><h2 id="过期副本检测"><a class="markdownIt-Anchor" href="#过期副本检测"></a> 过期副本检测</h2><p>有时候chunk副本可能会过期，因为chunkserver没有执行相关命令。因此，对于每个chunk，master都维护一个chunk版本号来分别最新chunk和过期chunk</p><p>当给一个租贷给chunk时，会增加chunk的版本好，并且通知最新的chunk。master和所有副本都会在持久状态中记录最新的版本号。如果一个chunkserver因为异常，没有执行命令，他的版本号不会增加，让他重启或者重新发送他的chunk序列及其版本号时，master就会发现过期的chunk。如果master发现最新的版本号大于记录的版本号，master就会假设分配租贷的时候失败，所以会更新一个更高的版本号。</p><p>master在垃圾回收的时候，移除过期的副本，并且在回复给client请求chunk信息时，当作过期的副本不存在。还有一种保护方法，当master回复client什么chunkserver拥有什么chunk的租贷时，或者什么时候让一个chunkserver去读取另一个chunkserver的副本时，会包含版本号，这样client和chunkserver总是会读到最新的数据。</p><h1 id="容错和诊断"><a class="markdownIt-Anchor" href="#容错和诊断"></a> 容错和诊断</h1><p>设计系统最大的挑战就是频繁的组建故障。组件的质量和数量使得异常频出，我们不能完全相信机器，我们也不能完全相信磁盘。</p><h2 id="高可用性"><a class="markdownIt-Anchor" href="#高可用性"></a> 高可用性</h2><p>通过两个策略保证可用性</p><ol><li>快恢复</li><li>复制</li></ol><h3 id="快恢复"><a class="markdownIt-Anchor" href="#快恢复"></a> 快恢复</h3><p>不管master和chunkserver为什么终止，都会在几秒内重新启动并且恢复状态。实际上，我们不区分正常异常和不正常异常</p><h3 id="chunk副本"><a class="markdownIt-Anchor" href="#chunk副本"></a> chunk副本</h3><p>master会通过校验和来检查坏的副本或者当chunkserver下线时，master会克隆新的副本出来。</p><h3 id="master副本"><a class="markdownIt-Anchor" href="#master副本"></a> master副本</h3><p>master的副本是为了master的可用性。master的operation log和检查点都保存在别的机器上。只有在所有的记录日志写入到磁盘和其他机器上，master才可以继续完成需要改变状态的命令。</p><p>如果master的机器或者磁盘损坏，GFS的监控部件会重新启动一个新的master进程。client只知道master的名字，因此master可以通过改变DNS的绰号来切换到另一个机器。</p><p>其次，当master损坏时，由影子master（shadow master）来访问文件系统，但是影子master只有可读权限。</p><p>影子master会比masteer处理慢一些。但是他们增强了对文件的可读操作，那些文件不会经常改变或者client不建议得到过期的文件。</p><p>为了使自己了解系统的情况，影子master会读取operation log，并且执行改变数据的相同序列，使得行为与master完全一致。和master一样，在启动时会轮训chunkserver来定位chunk副本的位置，并且频繁的chunkserver握手来监控他们的状态。对于副本的深处或者更新仅仅依赖master</p><h2 id="数据一致性"><a class="markdownIt-Anchor" href="#数据一致性"></a> 数据一致性</h2><p>每个chunkserver通过校验和去检查数据是否一致。</p><p>在chunkserver相应client或者master的请求时，都会校验一下数据block。因此，chunkserver不会把坏数据传播给其他机器。受到相应后，请求者会读取别的副本，而master也会读取副本，并且复制，之后给chunkserver发送消息，通知其删除错误副本。</p><h1 id="结尾"><a class="markdownIt-Anchor" href="#结尾"></a> 结尾</h1><p>基本的概念就结束了，后面就是一些测试和结论，就懒得记笔记了。。。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;本文是对谷歌论文：The Google File System的笔记&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作者：Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung Google∗&lt;/strong</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="文件系统" scheme="https://www.mryan.cool/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce:Simplified Data Processing On Large Clusters</title>
    <link href="https://www.mryan.cool/2021/08/14/MapReduce-Simplified-Data-Processing-On-Large-Clusters/"/>
    <id>https://www.mryan.cool/2021/08/14/MapReduce-Simplified-Data-Processing-On-Large-Clusters/</id>
    <published>2021-08-14T01:04:10.000Z</published>
    <updated>2021-08-18T00:30:00.466Z</updated>
    
    <content type="html"><![CDATA[<p>**本文是对谷歌论文：MapReduce: Simplified Data Processing on Large Clusters 的笔记 **</p><p><strong>作者：Jeffery Bean and Sanjay Ghemawat</strong></p><p><strong>URL:<a href="http://nil.csail.mit.edu/6.824/2020/papers/mapreduce.pdf">http://nil.csail.mit.edu/6.824/2020/papers/mapreduce.pdf</a></strong></p><p><strong>在阅读中使用遵循3W原则，即why，what，how</strong></p><h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1><p>MapReduce是一个编程模型，实现了处理并生成大数据集合。map用来处理一个&lt;key,value&gt; pair并生成一系列中间&lt;key,value&gt; pair，reduce用来聚合所有key相同的pair。</p><p>按照mapreduce风格编写的代码可以直接在大型机器上运行。让运行时系统来负责输入数据的分区，处理程序的调度和失败异常。通过这般，程序猿即使对分布式系统不了解，也可以轻松在分布式系统上处理大量数据。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PS：mapreduce是一种编写风格</span><br><span class="line">why：许多人对分布式系统不了解，却仍然需要用分布式系统来处理大数据</span><br><span class="line">what：mapreduce是一个编程风格，按照该风格编写的代码，可以运行在分布式集群中，帮助不了解分布式的人更好完成大数据处理</span><br></pre></td></tr></table></figure><h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1><p>本文主要是讲述如何<strong>分布式计算，分散数据，处理异常</strong>。</p><p>为了掩盖大量复杂的分布式计算，分散数据，处理异常，复杂均衡的细节，我们提出了新的抽象，这种抽象灵感主要来自于lisp的map和reduce。我们意识到我们大多数计算是对输入的每个逻辑记录进行一个映射，从而得到一系列简介&lt;key,value&gt;pair，然后对所有key相同的pair进行reduce运算，即便将导出的数据进行一个整合。我们使用用户自定义的map，reduce函数模型，可以很好并行处理，并且将<strong>重启</strong>作为容错的一个主要机制。</p><p>这项工作的主要贡献是提供一个简单而强大的接口，使得可以自动化并行和大规模计算的分布，结合该接口的实现，在大型商用pc集群上实现高性能。</p><p>我们将从一下顺序来说明</p><ol><li>编程模型</li><li>针对基于集群的计算环境，mapreduce接口的实现</li><li>对编程模型的改进</li><li>性能测试</li><li>使用mapreduce进行的工作</li><li>相关工作和未来前景</li></ol><h1 id="编程模型"><a class="markdownIt-Anchor" href="#编程模型"></a> 编程模型</h1><p>计算获取输入的k-v，并且生成输出的k-v。mapreduce库的用户将计算分成两个函数：map，reduce。</p><h2 id="map"><a class="markdownIt-Anchor" href="#map"></a> Map</h2><p>获取input pair，然后生成一系列中间k-v值。mapreduce库将根据相同的key将所有中间值聚合，并且传送到reduce函数中。</p><h2 id="reduce"><a class="markdownIt-Anchor" href="#reduce"></a> reduce</h2><p>获取中间值 I ， 和该key的value集合。将这些value聚合成一个更小的value集合。通常，reduce只输出0或1个结果。传送给reduce的中间值重要通过一个迭代器，迭代器允许我们处理较大的数据，以免溢出内存。</p><h2 id="例子"><a class="markdownIt-Anchor" href="#例子"></a> 例子</h2><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/R7FAmX.png" alt="" /></p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/MQMaEp.png" alt="" /></p><h1 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h1><p>不同的环境，实现方式不一样。该文实现方式主要针对google环境。</p><ol><li>处理器是x86架构，每个机器2-4G内存。</li><li>用的是商业网络，通常是100Mb/s或者1000Mb/s。</li><li>一个集群包括数以百计的计算机，因此，机器故障很常见</li><li>存储是便宜的IDE硬盘，直接间接到单个机器。文件系统在硬件不可靠的基础上使用复制来保证可用性和稳定性。</li><li>用户提交一个job给调度系统。每个job由一系列task构成，并且被调度器映射到集群中可用机器上。</li></ol><h2 id="执行"><a class="markdownIt-Anchor" href="#执行"></a> 执行</h2><p>map函数被分布到多个机器是通过自动划分成几个split完成。reduce函数被分布，是通过分区函数对key空间划分成R片（比如hash(key) mod R）。</p><p>运行流程：</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/91CPJ0.png" alt="" /></p><ol><li>maoreduce库首先将input分成M片，通常在16MB到64MB之间。然后在一组机器上启动该程序的许多副本。</li><li>其中有一个程序副本是特别的----master。这有M个map和R和reduce。其余都是由master分配的worker。由master挑选worker来分配map或者reduce task。</li><li>分配map的worker会读取输入文件的对应分割内容。他从输入数据中解析k-v，并且传递给用户自定义的map文件。由map函数生成的k-v对被被存在内存中。</li><li>缓存中的pair会定期写入硬盘，通过分区函数将其划分为R块。在硬盘上的缓存pair将位置传递给master，master负责将这些位置传递给reducer worker。</li><li>当reduce worker被master唤醒，得到了其缓冲pair的位置，就会调用远程call函数来读取map worker硬盘上的缓冲pair。当reduce worker读取了所有中间数据，就会通过key对中间数据进行排序，从而所有key相同的pair会聚集在一起。排序之所以必要，是因为有很多不同的key会映射到相同的reduce task中。如果中间数据太大，内存适应不了，需要使用外部排序。</li><li>reducer worker遍历所有排序后的中间数据，对每个单独的key和对应的value 集合传递给reduce函数。reduce函数的输出会添加这个reduce分区的到最终输出文件的结尾。</li><li>当所有的map任务和reduce任务都完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码。</li></ol><h2 id="master的结构"><a class="markdownIt-Anchor" href="#master的结构"></a> master的结构</h2><ol><li>必须保存每个map task和reduce task的状态（空闲，正在运行，完成），和worker的标识符（里面运行非空闲的task）</li><li>master是一个中间管道，通过它可以将中间文件区域的位置从map task传递到reduce task中。因此，对每个完成的map task，master必须存储由map task生成的中间数据区域的位置和长度。当map任务完成时，会更新位置和长度。信息以递增的方式推给reduce task。</li></ol><h2 id="容错"><a class="markdownIt-Anchor" href="#容错"></a> 容错</h2><p>由于MapReduce库的设计目的是帮助使用数百或数千台机器处理大量数据，因此该库必须优雅地容忍机器故障</p><h3 id="worker-failure"><a class="markdownIt-Anchor" href="#worker-failure"></a> Worker failure</h3><p>master定期ping每个worker，如果一段时间没收到响应，则表示该worker异常。</p><p>任何由worker完成的map task会被重置为空闲，从而可以被master调度到其他的worker中。类似，失败的map或者reduce task也会被重置成空闲，从而再分配。</p><p>在失败的机器上完成的map task需要被重新执行，因为他的输出是存储在失败机器的本地硬盘上，是不可访问的。完成的reduce task不需要重新执行，因为他的输出存储在全局文件系统上。</p><p>当一个map task开始被worker A执行，随后被worker B执行(因为worke A异常)，然后通知所有执行reduce的worker。任何没有从worker A读取数据reduce task需要从worker B读取数据。</p><h3 id="master-failure"><a class="markdownIt-Anchor" href="#master-failure"></a> Master failure</h3><p>为上面描述的master数据结构定期检查。如果master失败，一个新的拷贝可以从最近的检查状态开始。然后，因为只有一个master，因此他很少失败。因此，如果master失败，我们可以终止mapreduce计算。</p><h3 id="存在失败的语义"><a class="markdownIt-Anchor" href="#存在失败的语义"></a> 存在失败的语义</h3><p>如果用户定义的map和reduce是确定的，那么我们的分布式实现产生的结果与无障碍顺序执行的结果是一样的。</p><p>我们依赖map和reduce原子提交来实现这个属性。</p><p>每个执行中的task将他们的输出写到一个私有的临时文件。reduce task产生一个这样的文件，map task产生R这个的文件（1个reduce对应1个）。当map task完成时，worker发送一条消息给master，里面包含R个临时文件的名字。如果master收到一个已经完成的map task，则忽略该消息，否则会更新master数据结构中R个文件的名字。</p><p>当reduce task完成时，reduce worker自动将他的临时输出文件重命名为最终输出文件。如果在多台机器上执行相同的reduce task，则将对相同的最终输出文件执行多个重命名调用。我们依赖底层文件系统提供的原子重命名操作来保证最终的文件系统状态只包含一次reduce任务执行所产生的数据。</p><h3 id="位置"><a class="markdownIt-Anchor" href="#位置"></a> 位置</h3><p>网络宽带是一个稀缺的资源，我们利用输入数据存储在当地磁盘的优点来节约宽带。</p><p>master考虑到输入文件的位置信息，将map task调度到一个包含对应输入数据副本的机器上，不然的话，他就当map task调度到一个离有数据副本机器较劲的机器上（比如同一网络交换机）。</p><p>在集群大部分机器运行mapreduce操作时，大多数input data从本地读取而不是通过网路读取。</p><h3 id="task粒度"><a class="markdownIt-Anchor" href="#task粒度"></a> task粒度</h3><p>如上图，我们将map划分为m片，reduce划分为r片。理想情况下，M和R远大于worker的数量。让一个worker执行许多不同task可以提高动态负载均衡，同时加快worker异常时的恢复。许多完成的map task可以分布到其他的worker中。</p><p>实际上，M和R是有实际大小的。因为master必须处理O（M+R）的调度，内存需要有O（M*R）的空间。</p><p>一般来说，R是由用户限制，选择可以让每个输入数据在16MB-64MB之间的M，因为这样能最好符合空间局部性。</p><h2 id="备份task"><a class="markdownIt-Anchor" href="#备份task"></a> 备份task</h2><p>mapreduce时间较长的一个主要原因是<strong>掉队者</strong>。指一个机器花了很长时间去完成最后几个map或者reduce task。</p><p><strong>掉队者产生的原因有好几个：</strong></p><ol><li>坏的磁盘会经历频繁的纠错，导致读取速度从30MB/S减少到1MB/S。</li><li>调度系统可能在该机器上调度了其他task，导致了CPU，内存，网络宽带的竞争</li></ol><p><strong>解决办法：</strong></p><p>当mapreduce快结束的时候，master会对正在执行的task进行备份。</p><h1 id="改进"><a class="markdownIt-Anchor" href="#改进"></a> 改进</h1><p>尽管map和reduce对大多需求足够，但仍有一些有用的扩展</p><h2 id="分区函数-partitioning-function"><a class="markdownIt-Anchor" href="#分区函数-partitioning-function"></a> 分区函数  Partitioning Function</h2><p>mapreduce的用户定义了reduce task输出文件的个数。</p><p>中间数据的key通过分区函数可以分到不同的区域</p><h2 id="顺序保证"><a class="markdownIt-Anchor" href="#顺序保证"></a> 顺序保证</h2><p>我们保证在给定的分区中，中间的键/值对是按键或键数递增的方式处理的。这种排序保证可以很容易地为每个分区生成一个有序的输出文件，当输出文件格式需要支持按键的有效随机访问查找时，或者输出的用户发现对数据进行排序很方便时，这是很有用的。</p><h2 id="组合函数-combiner-function"><a class="markdownIt-Anchor" href="#组合函数-combiner-function"></a> 组合函数  combiner Function</h2><p>在一些情况，由map task产生的中间数据有很多重复。比如上面的wordCount伪代码，每个map task都会产生数以百计的&lt;the , 1&gt;。这些全部要通过网络传到一个reduce task，然后通过reduce函数将它们相加，产生一个总和。我们允许用户去定义一个组合函数(combiner function)去在他们传输到网络之前，做一个部分的聚集。</p><p>combiner函数在<strong>执行map task的机器上</strong>执行。一般来说，combiner函数和reduce函数代码相同。唯一的不同是reduce函数和combiner函数对输出文件处理不同。reduce函数的输出文件是最终输出文件，combiner函数写到一个中间文件，最后发送到reduce task中。</p><h2 id="输入输出类型"><a class="markdownIt-Anchor" href="#输入输出类型"></a> 输入输出类型</h2><p>mapreduce库提供了以几种不同格式读取输入数据。</p><p><strong>text模式：</strong></p><p>将每一行作为k-v键值对。key是文件的偏移量，value是该行的内容。</p><p>如果想添加其他类型，需要实现reader接口。reader接口并不是必须提供从文件读取数据，也可以从数据库，或者是内存映射中读取。</p><h2 id="副作用"><a class="markdownIt-Anchor" href="#副作用"></a> 副作用</h2><h2 id="跳过坏记录"><a class="markdownIt-Anchor" href="#跳过坏记录"></a> 跳过坏记录</h2><p>有时候因为用户代码的bug，导致map和reduce函数在某些记录上崩溃。这样的bug导致mapreduce无法完成。通常办法是修复他，但有时不可行，因为这个bug可能是第三方库的bug。因此，有时候在做统计时，可以忽略一些数据。我们提供了一种可选的模式，当mapreduce库发觉一些记录会导致崩溃时，会跳过这些数据以便继续运行。</p><p>每个worker进程安装一个信号处理来捕获分段错误和总线错误。在调用用户map和reduce之前，mapreduce库将参数序号存储在一个全局变量中。如果用户代码发出一个信号，信号处理发送一个包含参数序号“last gasp” UDP包给master。当master看到在一个记录上出现多次错误，他会在下一次map和reduce task执行时，跳过这些记录。</p><h2 id="本地执行"><a class="markdownIt-Anchor" href="#本地执行"></a> 本地执行</h2><p>调试map和recude函数很难，因为实际的计算在分布式系统进行，master进行动态的工作分配。为了方便调试，分析，小规模测试，我们开发了一个mapreduce的替代实现，可以在本地机器顺序执行mapreduce的所有工作。控制权交给用户，以便计算可以限制在特定的map task中。用户标记他们的程序，可以轻松调试。</p><h2 id="状态信息"><a class="markdownIt-Anchor" href="#状态信息"></a> 状态信息</h2><p>master内部运行一个http服务器，并且暴露一系列状态给用户使用。状态页面展示了计算的过程，比如多少task完成，多少task在进行，中间数据的输入文件大小等等。这些页面还包含到每个task生成的标准错误和标准输出文件的链接。用户可以根据这些来预测计算要花费的时间，是否应该在计算机中加入更多资源。这些页面也可以指出是否计算比预期要慢。</p><p>此外，顶级状态页面显示哪些worker失败了，以及当他们失败时正在处理哪些map和reduce task。当试图诊断用户代码中的错误时，此信息是有用的。</p><h2 id="计数器"><a class="markdownIt-Anchor" href="#计数器"></a> 计数器</h2><p>mapreduce提供了一个计数器来方便计算各种事件的发生。比如，用户代码可能希望计算处理的单词总数或索引的德语文档的数量。</p><p>为了实现，用户代码可以创建一个counter对象，并且在每一个map或者reduce task中递增。</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/JXJigY.png" alt="" /></p><p>counter来自个别worker的值会传播给master（通过ping的response）。master根据成功完成的map或者reduce task聚合counter的值，并且在mapreduce完成后返回给用户代码。当前counter的值也会显示在master的状态页面中，一遍用户可以看到实时计算的进展。当聚合counter值是，master消除了相同map或者reduce task的重复执行（可能因为用户的备份，或者因为失败而重新执行）。</p><p>有一些counter值是mapreduce库自动维护的，比如输入的k-v数量，输出的k-v数量。</p><p>用户发现计数器工具对于合理性检查MapReduce操作的行为很有用。比如用户希望输出的pair和输入的pair数量相同。</p><h1 id="性能"><a class="markdownIt-Anchor" href="#性能"></a> 性能</h1><p>我们对两个程序进行了测量。一个是对1TB数据进行模式匹配，一个是对1TB数据进行排序。这两类程序是mapreduce的一大子集----一个是将数据从一种表示变成另一个表示，一种是从大数据中提取相关元素。</p><h1 id="经验"><a class="markdownIt-Anchor" href="#经验"></a> 经验</h1><h2 id="大规模的索引"><a class="markdownIt-Anchor" href="#大规模的索引"></a> 大规模的索引</h2><p>谷歌将它们的产品索引系统产生的数据重写了一份。</p><p>使用mapreduce的好处</p><ol><li>索引代码更简单</li><li>maoreduce库的性能很好，我们可以将不想管的计算分开，而不是混在一起以免有额外的数据传递。</li><li>索引进程更简单操作，因为大部分机器故障，网络故障都被mapreduce库解决</li></ol><h1 id="相关工作"><a class="markdownIt-Anchor" href="#相关工作"></a> 相关工作</h1><p>主要介绍了几个思想的来源，懒得翻译了。。。</p><h1 id="结论"><a class="markdownIt-Anchor" href="#结论"></a> 结论</h1><ol><li>对编程模型的限制使其易于对等和分布计算，并使这种计算具有容错性</li><li>网络宽带是一个稀缺资源，一系列优化主要针对减少网络传递的数据。局部性优化让我们从本地磁盘读取数据，将中间数据的单个副本写入本地磁盘可以节省网络带宽</li><li>冗余执行可用于减少慢速机器的影响，并处理机器故障和数据丢失。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;**本文是对谷歌论文：MapReduce: Simplified Data Processing on Large Clusters 的笔记 **&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作者：Jeffery Bean and Sanjay Ghemawat&lt;/strong&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式系统" scheme="https://www.mryan.cool/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="mapreduce" scheme="https://www.mryan.cool/tags/mapreduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop-MapReduce Algorithm Design Pattern</title>
    <link href="https://www.mryan.cool/2021/08/12/hadoop-MapReduce-Algorithm-Design-Pattern/"/>
    <id>https://www.mryan.cool/2021/08/12/hadoop-MapReduce-Algorithm-Design-Pattern/</id>
    <published>2021-08-12T04:38:40.000Z</published>
    <updated>2021-08-13T03:09:03.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="co-occurrenct-matrix"><a class="markdownIt-Anchor" href="#co-occurrenct-matrix"></a> Co-occurrenct Matrix</h1><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/YVMIr3.png" alt="" /></p>{M_{ij}}$$表示在一个句子中共同出现的次数。![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/p8cS4v.png)**作用**：可以用来语言处理，计算相似性**例子**：![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/T1U2LF.png)右图：v和w，x，y共同出现了一次，w和v，x，y，u，t共同出现了一次## 两种MapReducer算法### Pairs Approach![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/65tjdE.png)原理：类似wordCount对每一个单词遍历，然后将它和邻居生成一个pair，同时次数设置为1，写入硬盘。类似于wordCount将每一个分词都算一次，写入硬盘### Stripes Approach![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/IWZfxF.png)对Pairs Approach优化。类似In-mapper without preserving state，对每一个单词遍历，找到一个邻居，次数先不着急写入硬盘，而是用map存储，如果又碰到该邻居，从而对map的value加1，从而减少写入硬盘的次数，并且减少output。# Co-occurrence Relative Frequencycies## 问题：![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/SCkw2Z.png)如上图1. 问题1   1. 有多少句子包含了cat和blue (4)   2. 多少句子包含了boat和blue (4)2. 问题2   1. 当我们在句子看到"cat"时，看到"blue"的可能性有多大  ($${\frac{4}{624}}$$)   2. 当我们看到"boat"，看到“blue”可能性有多大 ($${\frac{4}{4}}$$)概率公式：![](https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/jwkdBk.png)## 难点：如何算出单词总共出现的次数，例如“dog”### 方法1:1. 要计算dogs出现的次数，将(dog,*)全部保存在内存中2. 将(dog,*)出现的频率相加### 方法21. mapper对每一次(dog,xxx)额外输出一个（dog，*）2. 在排序时，将(dog,\*)排在第一个，这样就可以聚合(dog,\*)，从而算出dog出现的频率。该设计方法叫做逆序，1. 通过该方法，我们可以在对需要数据进行计算时，先访问reducer的计算结果2. 关键点是将计算顺序转换成排序问题]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;co-occurrenct-matrix&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#co-occurrenct-matrix&quot;&gt;&lt;/a&gt; Co-occurrenct Matrix&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://</summary>
      
    
    
    
    <category term="Hadoop" scheme="https://www.mryan.cool/categories/Hadoop/"/>
    
    
    <category term="大数据" scheme="https://www.mryan.cool/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>hadoop-MapReduce</title>
    <link href="https://www.mryan.cool/2021/08/11/hadoop-MapReduce/"/>
    <id>https://www.mryan.cool/2021/08/11/hadoop-MapReduce/</id>
    <published>2021-08-11T10:03:05.000Z</published>
    <updated>2021-08-12T04:30:08.363Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/CzErwY.png" alt="" /></p><h1 id="mapreduce介绍"><a class="markdownIt-Anchor" href="#mapreduce介绍"></a> MapReduce介绍</h1><h2 id="传统大数据问题"><a class="markdownIt-Anchor" href="#传统大数据问题"></a> 传统大数据问题</h2><ol><li><strong>map</strong><ol><li>遍历大量数据</li><li>从每个元素中提取</li></ol></li><li>打散，重排中间结果</li><li><strong>recude</strong><ol><li>聚合中间结果</li><li>生成最终输出</li></ol></li></ol><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/BRL3jV.png" alt="" /></p><h2 id="mapreduce的优点"><a class="markdownIt-Anchor" href="#mapreduce的优点"></a> MapReduce的优点</h2><p>简单</p><ol><li>只需要实现mapper和reducers</li><li>可选择是否实现combiner和partitioner</li></ol><h2 id="mapreduce的任务"><a class="markdownIt-Anchor" href="#mapreduce的任务"></a> MapReduce的任务</h2><ol><li>处理调度<ol><li>分配任务给map和reduer task</li><li>每个job都被分成若干个小task</li></ol></li><li>处理 “数据分布”<ol><li>将代码移到数据块，从而保证数据局部性</li></ol></li><li>处理同步<ol><li>收集，排序，打散中间数据。reducer知道mapper完成才可以执行</li></ol></li><li>处理异常和错误<ol><li>发现工作错误并重启</li></ol></li></ol><h1 id="mapreduce基础"><a class="markdownIt-Anchor" href="#mapreduce基础"></a> MapReduce基础</h1><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/6xe7g1.png" alt="" /></p><p>(k1 , v1)是map的input</p><p>(k2 , [v2])是mapper打散&amp;重排后的输出</p><h2 id="combiner"><a class="markdownIt-Anchor" href="#combiner"></a> Combiner</h2><p>所有来自mapper的key-value pairs需要通过网络拷贝，如果中间数据太大，效率会很低。因此在拷贝之前，先对输出做一个本地的聚合。</p><h2 id="partition-shuffle-sorting"><a class="markdownIt-Anchor" href="#partition-shuffle-sorting"></a> Partition , shuffle , sorting</h2><p><strong>shuffle</strong>：把map的输出移到reduer的过程。所有kay相同的value都会一起reduce，不管它来自哪个mapper</p><p><strong>partitioner</strong>：对每个pair，由MapReduer平台来决定去哪个partition，如果程序员想自定义，需要实现patitioner。</p><p><strong>sorting</strong>：在reducer开始之前，所有的pair需要根据key进行排序</p><h2 id="黑盒"><a class="markdownIt-Anchor" href="#黑盒"></a> 黑盒</h2><ol><li>mapper和reducer在哪里运行</li><li>什么时候mapper和reducer开始结束</li><li>特定mapper正在处理哪个输入</li><li>特定reducers在处理哪个中间值</li></ol><h1 id="mapreduce本地聚合"><a class="markdownIt-Anchor" href="#mapreduce本地聚合"></a> MapReduce本地聚合</h1><p><strong>关键点</strong>：</p><ol><li>主要用in-mapper combining 或者 combiner</li><li>可以保存多输入的状态</li></ol><h3 id="combiner-2"><a class="markdownIt-Anchor" href="#combiner-2"></a> Combiner</h3><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/Kr2h4Y.png" alt="" /></p><h3 id="in-mapper-combining"><a class="markdownIt-Anchor" href="#in-mapper-combining"></a> In-mapper Combining</h3><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/zuntEk.png" alt="" /></p><h3 id="in-mapper-combiningpreserve-state"><a class="markdownIt-Anchor" href="#in-mapper-combiningpreserve-state"></a> In-mapper Combining(preserve state)</h3><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/YfvvHx.png" alt="" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/CzErwY.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;mapreduce介绍&quot;&gt;&lt;a class=&quot;markdown</summary>
      
    
    
    
    <category term="Hadoop" scheme="https://www.mryan.cool/categories/Hadoop/"/>
    
    
    <category term="大数据" scheme="https://www.mryan.cool/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>hadoop-Yarn</title>
    <link href="https://www.mryan.cool/2021/08/11/hadoop-Yarn/"/>
    <id>https://www.mryan.cool/2021/08/11/hadoop-Yarn/</id>
    <published>2021-08-11T04:21:17.000Z</published>
    <updated>2021-08-11T10:02:31.562Z</updated>
    
    <content type="html"><![CDATA[<h1 id="yarn"><a class="markdownIt-Anchor" href="#yarn"></a> YARN</h1><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/Y0DA4H.png" alt="" /></p><p>负责管理集群中的计算机资源，并且用来调度用户应用</p><h1 id="hadoop10"><a class="markdownIt-Anchor" href="#hadoop10"></a> Hadoop1.0</h1><p>在hadoop1.0中，MapReduce既负责处理，又负责资源管理。（此时没有Yarn）</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/zXbutz.png" alt="" /></p><h2 id="jod-tracker-the-single-master"><a class="markdownIt-Anchor" href="#jod-tracker-the-single-master"></a> Jod Tracker - the single master</h2><ol><li>分配资源</li><li>处理调度</li><li>监控正在进行的工作</li></ol><p>Job Tracker分配map和recude任务给子进程–即Task Tracker（定期汇报他的过程给Job Tracker）</p><h2 id="设计后果"><a class="markdownIt-Anchor" href="#设计后果"></a> 设计后果</h2><ol><li>单个Job Trackr导致可扩展性瓶颈<ol><li>IBM根据Yahoo提到，在达到5000node和40000task时，性能出现瓶颈</li></ol></li><li>Hadoop框架仅限于MapReduce处理范式</li></ol><h1 id="hadoop20-引入yarn"><a class="markdownIt-Anchor" href="#hadoop20-引入yarn"></a> Hadoop2.0 引入Yarn</h1><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/0j4MVS.png" alt="" /></p><p>Yarn最初的目的是通过管理资源和工作调度来解放MapReduce</p><p>随着Yarn的引入，Hadoop更加有弹性和效率，具备高扩展性</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/bXOrjO.png" alt="" /></p><h2 id="功能"><a class="markdownIt-Anchor" href="#功能"></a> 功能</h2><ol><li>调度<ol><li>根据需求分配资源给应用</li></ol></li><li>应用管理<ol><li>从资源管理器协商第一个容器，以执行特定于应用程序的应用程序主机</li><li>在集群中管理Application Master</li><li>出现故障时，重启application Master</li></ol></li></ol><p>如图</p><h3 id="container"><a class="markdownIt-Anchor" href="#container"></a> Container</h3><p>硬件资源的集合，比如RAM，CPU，硬盘等</p><h3 id="node-manager"><a class="markdownIt-Anchor" href="#node-manager"></a> Node Manager</h3><ol><li>负责集群中的节点</li><li>通过Resource Manager注册，并发送带有node节点健康状态的心跳给rourese manager</li><li>Application Master通过发送container launch context（CLC）CLC包括了应用需要的所有信息，然后向node manager中的container发送请求。Node manager然后创建并启动请求的container进程</li></ol><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/AANDiW.png" alt="" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;yarn&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#yarn&quot;&gt;&lt;/a&gt; YARN&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com</summary>
      
    
    
    
    <category term="Hadoop" scheme="https://www.mryan.cool/categories/Hadoop/"/>
    
    
    <category term="大数据" scheme="https://www.mryan.cool/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>hadoop-HDFS</title>
    <link href="https://www.mryan.cool/2021/08/11/hadoop-HDFS/"/>
    <id>https://www.mryan.cool/2021/08/11/hadoop-HDFS/</id>
    <published>2021-08-11T03:36:10.000Z</published>
    <updated>2021-08-11T10:04:01.718Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1><p>hadoop 是一个开源的框架，用于在商业集群上存储和大规模处理数据集。</p><p>hadoop由许多组件构成</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/wVwJpG.png" alt="" /></p><h1 id="storage-hdfs"><a class="markdownIt-Anchor" href="#storage-hdfs"></a> Storage - HDFS</h1><p>HDFS对其文件和应用遵循“写一次，读n次”的策略，所有曾经写过的文件不会修改。</p><h2 id="hdfs的特性"><a class="markdownIt-Anchor" href="#hdfs的特性"></a> HDFS的特性</h2><p>HDFS是一个分布式文件系统</p><ol><li>拥有好的容错率----HDFS被设计出来就是为了运行在低成本的硬件上。</li><li>具有对应用数据访问的高吞吐性----适合存储大量数据的应用</li><li>允许流访问文件系统数据</li></ol><h3 id="architecture-of-hdfs"><a class="markdownIt-Anchor" href="#architecture-of-hdfs"></a> Architecture of HDFS</h3><p>一个文件被分成多个block，这些快存储在DataNOdes的集合中。</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/cFpH7k.png" alt="" /></p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/NSDbPP.png" alt="" /></p><h4 id="masterslave-architecture-一个namenode-多个datanode"><a class="markdownIt-Anchor" href="#masterslave-architecture-一个namenode-多个datanode"></a> Master/Slave Architecture – 一个NameNode ， 多个DataNode</h4><p>一个NameNode</p><ol><li>维持整个文件系统命名空间<ol><li>所有对文件系统命令空间的改变都会被记录在NameNode中</li><li>应用可以指定备份的个数</li></ol></li><li>包括文件系统树和所有文件的元数据</li></ol><p>多个DataNode</p><ol><li>服务来自客户的读写请求</li><li>根据来自NameNode的指令，负责block的创建，删除，冗余</li></ol><h4 id="数据复制"><a class="markdownIt-Anchor" href="#数据复制"></a> 数据复制</h4><p>HDFS被设计成在一个跨机器的大型集群中存储大量数据</p><p>存储原理：将文件分成若干block，除了最后一个之外，所有的block都相同。</p><p><img src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/C8BLQ6.png" alt="" /></p><p>block的辅助由NameNode来管理。NameNode会定期从集群中的DataNode中接受心跳检测和块报告</p><p>![image-20210811121405224](/Users/yixuanyan/Library/Application Support/typora-user-images/image-20210811121405224.png)</p><p>如图，NameNode存储文件的元信息，物理文件放在Datanode。</p><h4 id="数据存放策略"><a class="markdownIt-Anchor" href="#数据存放策略"></a> 数据存放策略</h4><p>本地rack(包含多个datanode)存在一个备份，其他rock存放一个卑微，其他Rock的不同datanode存放一个备份。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;介绍&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#介绍&quot;&gt;&lt;/a&gt; 介绍&lt;/h1&gt;
&lt;p&gt;hadoop 是一个开源的框架，用于在商业集群上存储和大规模处理数据集。&lt;/p&gt;
&lt;p&gt;hadoop由许多组件构成&lt;/p&gt;
&lt;p&gt;&lt;img sr</summary>
      
    
    
    
    <category term="Hadoop" scheme="https://www.mryan.cool/categories/Hadoop/"/>
    
    
    <category term="大数据" scheme="https://www.mryan.cool/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Java项目中第三方库的使用、更新和风险的实证研究</title>
    <link href="https://www.mryan.cool/2021/08/03/Java%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%E3%80%81%E6%9B%B4%E6%96%B0%E5%92%8C%E9%A3%8E%E9%99%A9%E7%9A%84%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6/"/>
    <id>https://www.mryan.cool/2021/08/03/Java%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%E3%80%81%E6%9B%B4%E6%96%B0%E5%92%8C%E9%A3%8E%E9%99%A9%E7%9A%84%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6/</id>
    <published>2021-08-03T10:56:32.000Z</published>
    <updated>2021-08-27T03:01:05.880Z</updated>
    
    <content type="html"><![CDATA[<p><strong>该文章是对  &quot;An Empirical Study of Usages, Updates and Risks of Third-party Libraries in Java Projects的翻译&quot;</strong></p><h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1><p>第三方库是开发软件系统的核心部件。然而过期的第三方库仍在普遍使用，开发者通常不会意识到潜在危险。因此对第三方库的使用，更新进行定量和整体研究可以为持续改善生态稳定。本文基于java开源项目，提出了库使用分析和库更新分析。这两个技术从开源项目和第三方库的角度，针对定量分析使用和更新。同时，还提出了库风险分析，针对定量过期库的风险，同时响应开发者的风险。</p><p>为了验证我们研究的有用性，我们发布了一个bug驱动的警报系统来协助开发者在更新时做出可信的决策。</p><h1 id="1-intruduction"><a class="markdownIt-Anchor" href="#1-intruduction"></a> 1 intruduction</h1><p>虽然当前很多研究研究了第三方库的版本，类，接口，API，分析了更新和不更新的理由，最新第三方库的用法，类似npm和android，但是现有的研究很少对使用和更新做定量的分析，或者从全局的角度进行分析。因此，对于软件系统如何密集地使用和更新第三方库，以及跨软件系统如何密集地使用和更新第三方库，缺乏具体和全面的证据。这种评估隐藏了维护第三方库的问题，阻碍了实际的解决方案。</p><p>很多系统系统都是安全驱动，仅仅当bug出现才会通知开发者，从而让开发者忽略了潜在的危险。</p><p>为了这些情况，定量和全面的研究是很有必要的。本文主要回答了以下三个问题做了这样的描述：</p><ol><li>RQ1 库使用分析：什么是第三方库的使用强度和使用过期程度</li><li>RQ2 库更新分析：什么是第三方库的更新强度和更新延迟</li><li>RQ3 库风险分析：什么是第三方库的潜在风险，以及开发者对此的反应如何</li></ol><p>总的来说，本文主要有如下贡献</p><ol><li>提出了一个对java开源项目第三方库的使用，更新，风险的一个大规模的定量和全局的分析</li><li>向开发人员和研究人员提供了实际意义，发布了我们的数据集，以促进应用程序和改善生态系统，并提出了一个原型系统，以证明我们的发现的实用性。</li></ol><p>本来按照如下步骤介绍</p><ol><li>**sec2：**介绍了研究设计</li><li>**sec3，4，6：**分别了对库的使用，更新，风险进行分析</li><li>**sec6：**讨论了该研究的意义和应用以及相关威胁</li><li>**sec7：**回顾了相关工作</li><li>**sec8：**得出结论</li></ol><h1 id="2-研究方法论"><a class="markdownIt-Anchor" href="#2-研究方法论"></a> 2 研究方法论</h1><h2 id="研究设计"><a class="markdownIt-Anchor" href="#研究设计"></a> 研究设计</h2><p>**RQ1：**分析一个项目依赖库的程度和库被项目使用的程度，主要是针对定量分析一个库在项目开发的重要性和库不断发展对项目产生的影响。然后我们从项目和库的角度来测量使用的库版本和最新版本相差多远，主要是针对定量分析项目中过期库的共性并且引出RQ2.</p><p>**RQ2：**调查项目的历史库版本的更新。从项目的角度来看，测量库版本更新的强度，其次从三方库的角度来看，在跨项目之间库版本更新的强度，这旨在量化更新库版本的实践。然后，从项目和库的角度来测量库版本更新落后于库版本发布的时间，这旨在量化开发者对新版本发布的反应速度，从而引出RQ3</p><p>**RQ3：**调查流行库的严重bug。首先测量多少个严重的bug存在库版本发布中，这旨在量化使用过期库和延迟更新库的潜在危险。然后，探索开发者对项目中bug的反应，这旨在描述项目开发人员对有bug的库版本的反应，以及他们对过时库版本的警报系统的需求。</p><h1 id="3-库使用分析"><a class="markdownIt-Anchor" href="#3-库使用分析"></a> 3 库使用分析</h1><p>主要从pom.xml和build.gradle来提取maven和gradle项目。对于maven项目，主要提取<strong>groupId，artifactId，Version</strong>，对gradle项目，主要提取<strong>group，name，version</strong>。</p><p>一个库依赖d由四元组表示,&lt;p,f,com,v&gt;</p><ol><li>p，f：声明d的项目和配置文件<ol><li>p.date是p的仓库被爬取的日期</li></ol></li><li>com表示d的commit<ol><li>Com.date表示com被提交的日期</li></ol></li><li>v表示d版本，由&lt;l,ver&gt;表示<ol><li>l表示库，由&lt;group,name&gt;表示<ol><li>group表示l的组织，name表示l的名字</li></ol></li><li>ver表示l的版本号</li></ol></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;该文章是对  &amp;quot;An Empirical Study of Usages, Updates and Risks of Third-party Libraries in Java Projects的翻译&amp;quot;&lt;/strong&gt;&lt;/p&gt;
&lt;h1 </summary>
      
    
    
    
    <category term="论文" scheme="https://www.mryan.cool/categories/%E8%AE%BA%E6%96%87/"/>
    
    <category term="第三方库分析" scheme="https://www.mryan.cool/categories/%E8%AE%BA%E6%96%87/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E5%88%86%E6%9E%90/"/>
    
    
    <category term="第三方库分析" scheme="https://www.mryan.cool/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>交互式的、努力意识的库版本协调</title>
    <link href="https://www.mryan.cool/2021/06/10/%E4%BA%A4%E4%BA%92%E5%BC%8F%E7%9A%84%E3%80%81%E5%8A%AA%E5%8A%9B%E6%84%8F%E8%AF%86%E7%9A%84%E5%BA%93%E7%89%88%E6%9C%AC%E5%8D%8F%E8%B0%83/"/>
    <id>https://www.mryan.cool/2021/06/10/%E4%BA%A4%E4%BA%92%E5%BC%8F%E7%9A%84%E3%80%81%E5%8A%AA%E5%8A%9B%E6%84%8F%E8%AF%86%E7%9A%84%E5%BA%93%E7%89%88%E6%9C%AC%E5%8D%8F%E8%B0%83/</id>
    <published>2021-06-10T08:48:04.000Z</published>
    <updated>2021-06-17T04:31:33.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言</strong>：本文是对论文 Interactive, Effort-Aware Library Version Harmonization 的翻译和自己的笔记，。</p><h1 id="交互式工作感知库版本协调"><a class="markdownIt-Anchor" href="#交互式工作感知库版本协调"></a> 交互式工作感知库版本协调</h1><h2 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h2><p>由于软件大量依赖第三方库，灵活的依赖生命机制，以及在项目中不断增长的模块数量，同一三方库的多个版本直接项目的不同模块。这样的库版本不一致性可能会增加依赖维护成本，或者当模块相互依赖时造成冲突。尽管自动构建工具(Maven等)提供了检测第三方库版本不一致性问题的部分支持，但是他们不提供任何服务来协调库版本不一致的问题。</p><p>对100多名java人员的调查，提出了LIB HARMO，一种可交互，努力感知的库版本协调技术。</p><h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2><p>该论文主要聚焦于maven，因为maven用的最多。</p><h3 id="1-问题多个模块使用同一三方库"><a class="markdownIt-Anchor" href="#1-问题多个模块使用同一三方库"></a> 1: 问题：多个模块使用同一三方库</h3><h4 id="解决思路需要工具来主动定位和协调不一致的库版本这些工具需要与人员进行交互并提供api级别的协调工作"><a class="markdownIt-Anchor" href="#解决思路需要工具来主动定位和协调不一致的库版本这些工具需要与人员进行交互并提供api级别的协调工作"></a> 解决思路：需要工具来主动定位和协调不一致的库版本，这些工具需要与人员进行交互，并提供API级别的协调工作。</h4><p>因此，我们提出了LIBHARMO。主要按三个步骤工作</p><ol><li>通过分析build配置文件(POM)来送给会识别库版本不一致。</li><li>对于每个库版本的不一致性，它建议使用协调工作最少的协调版本。</li><li>如果开发者决定去协调，会重命名POM，并且建议去更换删掉的库的API。</li></ol><h4 id="贡献"><a class="markdownIt-Anchor" href="#贡献"></a> 贡献：</h4><ol><li>我们对github的131名Java开发人员进行了第一次调查，以获取关于库版本不一致的实践和工具方面的第一手信息。</li><li>我们根据我们的调查点，提出了第一个交互式，努力意识的库版本协调技术LIBHARMO。</li><li>用LIBHARMO对443个高star的java maven项目进行评估，发现了621处库版本不一致。有5个已经被证实，1个被协调。</li></ol><h3 id="2开发者调查"><a class="markdownIt-Anchor" href="#2开发者调查"></a> 2:开发者调查</h3><h4 id="调查内容"><a class="markdownIt-Anchor" href="#调查内容"></a> 调查内容</h4><p><strong>根源</strong>：</p><pre><code>1. 对第三方库的不熟悉和三方库不向后兼容2. 没有意识到版本不一致的危害3. 不好的管理习惯，不熟悉maven</code></pre><p><strong>如何发现</strong>：</p><ol><li>版本冲突</li><li>API变更</li><li>对POM人工检查</li><li>maven的enforcer插件</li></ol><p><strong>不修复的理由</strong>：</p><ol><li>不向后兼容</li><li>巨大的API依赖</li><li>不同模块进度不一致</li><li>没有出现大bug</li></ol><p><strong>修复的理由</strong>：</p><ol><li>避免长时间运行巨大的维护成本</li><li>不会出现大的bug。</li></ol><p><strong>修复策略</strong>：</p><ol><li>使用比当前版本更新的版本（77.6%）</li><li>选择一个当前使用的版本（29%）</li></ol><p><strong>修复成本</strong>：</p><ol><li>数小时</li><li>数天</li><li>数分钟</li></ol><p>PS：查找版本不一致，确定协调版本，重构代码是最耗时的过程</p><p><strong>工具期望</strong>：</p><p>45.6%认为自动化协调工具有用，14%认为没用，因为他们已经适应了enforcer插件。</p><p>46.5%的人认为这取决于它在构建过程中的集成程度、自动化程度等。对于这种工具中最有用的功能，检测所有库版本的不一致（75.9%），并建议协调版本（71.4%）是最有用的，其次是报告详细的API级别修复工作（49.1%）和重构POM文件（42.0%）。令人惊讶的是，重构源代码（25.0%）比以前的所有特性都不那么被认为有用。</p><h4 id="调查结果"><a class="markdownIt-Anchor" href="#调查结果"></a> 调查结果</h4><ol><li>需要有工具来帮助开发人员主动定位和协调不一致的库版本，因为库版本不一致大多是手动检测的，或者是在严重后果后被动发现的。</li><li>开发者应该与工具交互去决定哪里协调和是否需要协调，因为库不一致可能跨模块或者模块之间进度不一致。</li><li>工具需要为开发人员提供API级的协调功能，因为API向后不兼容、API依赖强度和API行为一致性是开发人员决定是否协调的关键因素</li><li>为了方便使用，工具需要集成到构建过程中。</li></ol><h2 id="方法论"><a class="markdownIt-Anchor" href="#方法论"></a> 方法论</h2><p>它首先生成POM继承图，然后分析继承关系来解决每个POM中的库依赖关系，最后识别库版本不一致和错误一致。</p><h3 id="生成pom继承图"><a class="markdownIt-Anchor" href="#生成pom继承图"></a> 生成POM继承图</h3><p>maven提供了继承机制去从父POM继承元素（依赖），但是不能循环继承，因此我们可以根据POM图形成一个有向无环图。</p><h3 id="解析库依赖"><a class="markdownIt-Anchor" href="#解析库依赖"></a> 解析库依赖</h3><p>创建一个六元组(lib,ver,pro,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>l</mi><mi>i</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{lib}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{ver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>p</mi><mi>r</mi><mi>o</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{pro}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>)。</p><ol><li>Lib:表示库，又groudid和atrifactid声明。</li><li>ver:表示lib的版本号</li><li>pro:表示lib的property</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>l</mi><mi>i</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{lib}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：指向声明了lib的POM</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{ver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：指向声明了version的POM</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>p</mi><mi>r</mi><mi>o</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{pro}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>：指向声明了property的POM</li></ol><h3 id="识别不一致性和错误一致性"><a class="markdownIt-Anchor" href="#识别不一致性和错误一致性"></a> 识别不一致性和错误一致性</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;：本文是对论文 Interactive, Effort-Aware Library Version Harmonization 的翻译和自己的笔记，。&lt;/p&gt;
&lt;h1 id=&quot;交互式工作感知库版本协调&quot;&gt;&lt;a class=&quot;markdo</summary>
      
    
    
    
    <category term="论文" scheme="https://www.mryan.cool/categories/%E8%AE%BA%E6%96%87/"/>
    
    <category term="第三方库分析" scheme="https://www.mryan.cool/categories/%E8%AE%BA%E6%96%87/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E5%88%86%E6%9E%90/"/>
    
    
    <category term="第三方库分析" scheme="https://www.mryan.cool/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
