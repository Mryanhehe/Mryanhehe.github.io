<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>NLP入门-文本分类 | Mr言的博客</title><meta name="description" content="介绍 文本分类是NLP领域里普遍而应用广泛的课题，指计算机将一篇文章归于预先给定的某一类或几类的过程。主要的应用领域为网页分类、微博情感分析、用户评论挖掘、信息检索、Web文档自动分类、数字图书馆、自动文摘、分类新闻组、文本过滤、单词语义辨析以及文档的组织和管理等。  传统机器学习实现文本分类 传统机器学习主要是人工特征工程 + 渐层分类模型。 分为特征工程和分类器两部分  特征工程 将本文表示"><meta name="keywords" content="自然语言处理"><meta name="author" content="严轶轩"><meta name="copyright" content="严轶轩"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://hm.baidu.com"/><link rel="dns-prefetch" href="https://hm.baidu.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="KMNZCFXyxopGAiX0"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="NLP入门-文本分类"><meta name="twitter:description" content="介绍 文本分类是NLP领域里普遍而应用广泛的课题，指计算机将一篇文章归于预先给定的某一类或几类的过程。主要的应用领域为网页分类、微博情感分析、用户评论挖掘、信息检索、Web文档自动分类、数字图书馆、自动文摘、分类新闻组、文本过滤、单词语义辨析以及文档的组织和管理等。  传统机器学习实现文本分类 传统机器学习主要是人工特征工程 + 渐层分类模型。 分为特征工程和分类器两部分  特征工程 将本文表示"><meta name="twitter:image" content="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/52Ol7V.jpg"><meta property="og:type" content="article"><meta property="og:title" content="NLP入门-文本分类"><meta property="og:url" content="https://www.mryan.cool/2021/10/11/NLP%E5%85%A5%E9%97%A8-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><meta property="og:site_name" content="Mr言的博客"><meta property="og:description" content="介绍 文本分类是NLP领域里普遍而应用广泛的课题，指计算机将一篇文章归于预先给定的某一类或几类的过程。主要的应用领域为网页分类、微博情感分析、用户评论挖掘、信息检索、Web文档自动分类、数字图书馆、自动文摘、分类新闻组、文本过滤、单词语义辨析以及文档的组织和管理等。  传统机器学习实现文本分类 传统机器学习主要是人工特征工程 + 渐层分类模型。 分为特征工程和分类器两部分  特征工程 将本文表示"><meta property="og:image" content="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/52Ol7V.jpg"><meta property="article:published_time" content="2021-10-11T09:08:57.000Z"><meta property="article:modified_time" content="2021-10-25T14:38:36.278Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://www.mryan.cool/2021/10/11/NLP%E5%85%A5%E9%97%A8-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><link rel="prev" title="python依赖树--pipdeptree" href="https://www.mryan.cool/2021/10/14/python%E4%BE%9D%E8%B5%96%E6%A0%91-pipdeptree/"><link rel="next" title="机器。自然力与科学的应用" href="https://www.mryan.cool/2021/10/11/%E6%9C%BA%E5%99%A8%E3%80%82%E8%87%AA%E7%84%B6%E5%8A%9B%E4%B8%8E%E7%A7%91%E5%AD%A6%E7%9A%84%E5%BA%94%E7%94%A8/"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?c11dcf5678886a7b82be8df8aa725fcc";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Mr言的博客" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://res.cloudinary.com/bravey/image/upload/v1588158174/avatar3.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">8</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关系</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text"> 介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text"> 传统机器学习实现文本分类</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text"> 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text"> 文本预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text"> 特征提取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E5%BC%8F"><span class="toc-number">3.3.</span> <span class="toc-text"> 文本特征选择方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%89%B9%E5%BE%81%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0"><span class="toc-number">3.3.1.</span> <span class="toc-text"> 常用特征评估函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E9%A2%91%E7%8E%87df%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E6%B3%95"><span class="toc-number">3.3.1.1.</span> <span class="toc-text"> 文档频率(DF)特征提取法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8Aig%E6%B3%95"><span class="toc-number">3.3.1.2.</span> <span class="toc-text"> 信息增益(IG)法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA"><span class="toc-number">3.3.2.</span> <span class="toc-text"> 文本表示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.2.1.</span> <span class="toc-text"> 向量空间模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.2.1.1.</span> <span class="toc-text"> 词袋模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tf-idf"><span class="toc-number">3.3.2.1.2.</span> <span class="toc-text"> TF-IDF</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E5%88%86%E5%B8%83%E5%BC%8F%E8%A1%A8%E7%A4%BA"><span class="toc-number">3.3.2.2.</span> <span class="toc-text"> 文本分布式表示</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%AE%A1%E6%95%B0"><span class="toc-number">3.3.2.2.1.</span> <span class="toc-text"> 基于计数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E9%A2%84%E6%B5%8B"><span class="toc-number">3.3.2.2.2.</span> <span class="toc-text"> 基于预测</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">4.</span> <span class="toc-text"> 机器学习分类器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">5.</span> <span class="toc-text"> 深度学习分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#cnn"><span class="toc-number">5.1.</span> <span class="toc-text"> CNN</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/52Ol7V.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Mr言的博客</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关系</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">NLP入门-文本分类</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-10-11 17:08:57"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2021-10-11</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-10-25 22:38:36"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2021-10-25</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1>
<p>文本分类是NLP领域里普遍而应用广泛的课题，指计算机将一篇文章归于预先给定的某一类或几类的过程。主要的应用领域为网页分类、微博情感分析、用户评论挖掘、信息检索、Web文档自动分类、数字图书馆、自动文摘、分类新闻组、文本过滤、单词语义辨析以及文档的组织和管理等。</p>
<h1 id="传统机器学习实现文本分类"><a class="markdownIt-Anchor" href="#传统机器学习实现文本分类"></a> 传统机器学习实现文本分类</h1>
<p>传统机器学习主要是人工特征工程 + 渐层分类模型。</p>
<p>分为<strong>特征工程</strong>和<strong>分类器</strong>两部分</p>
<h1 id="特征工程"><a class="markdownIt-Anchor" href="#特征工程"></a> 特征工程</h1>
<p>将本文表示为计算机可以识别的、能够代表该文档特征的特征矩阵的过程。在基于传统机器学习的文本分类中，主要分为<strong>文本预处理 ， 特征提取， 文本表示</strong></p>
<h2 id="文本预处理"><a class="markdownIt-Anchor" href="#文本预处理"></a> 文本预处理</h2>
<p>提出文本中的关键词来表示文本的过程。中文主要包括文本分词和去停用词</p>
<p><strong>文本分词</strong>，是因为很多研究表明特征粒度为词粒度远好于字粒度（其实很好理解，因为大部分分类算法不考虑词序信息，基于字粒度显然损失了过多“n-gram”信息）</p>
<p><strong>停止词</strong>是<strong>文本中一些高频的代词、连词、介词等对文本分类无意义的词</strong>，通常维护一个停用词表，特征提取过程中删除停用表中出现的词，本质上属于特征选择的一部分。</p>
<h2 id="特征提取"><a class="markdownIt-Anchor" href="#特征提取"></a> 特征提取</h2>
<p>主要包括特征选择和特征权重计算</p>
<p><strong>特征选择</strong>：基本思路是根据某个指标独立的对原始特征项进行评分排序，从中选择得分最高的一些特征项，过滤掉其余的特征项，常用特征项是 文档频率，互信息，信息增益等</p>
<p><strong>特征权重计算</strong>：主要是经典的TF-IDF及其扩展方法，一个词的重要度与在类别内的词频成正比，与所有类别出现的次数成反比。</p>
<h2 id="文本特征选择方式"><a class="markdownIt-Anchor" href="#文本特征选择方式"></a> 文本特征选择方式</h2>
<p>在文本处理过程中,将文本集合中的每个文本实行分词处理后,通常是统计出每个文本出现的词以及相应的词频,然后将每个文本出现的词合并成一个词空间,所以词空间中出现的不同词相当多。表示一篇文本的时候,无论文本用向量空间模型还是概率统计模型来表示,文本的特征的维度都和词空间的维度一样。而每个文本中出现的词只占词空间中很少一部分,文本特征表示非常稀疏。使分类算法的时间复杂度和空间复杂度增加,而且对文本特征表示的不准确性严重影响了文本分类性能。因此,需要对文本特征进行筛选,选出最能代表文本类别的特征,这个过程就是特征选择。特征选择的一般步骤是</p>
<ol>
<li>从训练文本集中去的所有的特征项，构成文本特征集合F</li>
<li>对集合中的每一项用特征评估函数进行打分，按照分支由高到低排序，得到有序集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{F_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></li>
<li>假设需要选取n个分类需要的特征项，从<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{F_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>集合中选取前n个特征项，构成最终的分类特征项<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mi>s</mi></msub><mo separator="true">,</mo><msub><mi>F</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">F_s,F_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>将用于训练分类器和分类器测试</li>
</ol>
<h3 id="常用特征评估函数"><a class="markdownIt-Anchor" href="#常用特征评估函数"></a> 常用特征评估函数</h3>
<h4 id="文档频率df特征提取法"><a class="markdownIt-Anchor" href="#文档频率df特征提取法"></a> 文档频率(DF)特征提取法</h4>
<p>一个特征的文档频率只指在文档集合中含有该特征项的文档数目。采用DF作为特征选择,基于如下基本假设:DF值低于某个域值的词条是低频词,它们不含或含有较少的类别信息。将这样的词条从原始特征空间中除去,不但能够降低特征空间的维数,而且还有可能提高分类的精度。文档频率是最简单的特征选择方法,由于其相对于训练语料规模具有线性的计算复杂度,它能够很容易被用于大规模语料统计。而在信息检索研究中通常却认为值低词条相对于值高的词条具有较多的信息量,不应该将它们完全移除。不同的应用对值的认识不同,因此应根据具体情况来选择该方法。</p>
<h4 id="信息增益ig法"><a class="markdownIt-Anchor" href="#信息增益ig法"></a> 信息增益(IG)法</h4>
<p>信息增益表示文本中包含某一特征值时文本类的平均信息量，定义为某一特征在文本中出现前后的信息墒之差</p>
<h3 id="文本表示"><a class="markdownIt-Anchor" href="#文本表示"></a> 文本表示</h3>
<p>将文本处理后结果转换成计算机可以理解的方式，是决定文本分类质量最重要的部分。传统做法是<strong>词袋模型</strong>或<strong>向量空间模型</strong>，最大的<strong>不足</strong>是忽略文本上下文关系，每个词之间彼此独立，并且无法表征语义信息。</p>
<h4 id="向量空间模型"><a class="markdownIt-Anchor" href="#向量空间模型"></a> 向量空间模型</h4>
<h5 id="词袋模型"><a class="markdownIt-Anchor" href="#词袋模型"></a> 词袋模型</h5>
<p>文档由一个个词组成，将一篇文档看成词袋。向量中每个位置的值为该编码对应的词在这段话中出现的次数。</p>
<h5 id="tf-idf"><a class="markdownIt-Anchor" href="#tf-idf"></a> TF-IDF</h5>
<p>前提条件</p>
<ol>
<li>有一个文档集合C，文档集合C里面一共有N篇文档</li>
<li>有一个词典D，词库里面有M个词</li>
</ol>
<p>tf是针对单篇文档而言，即<strong>某个词在这篇文档中出现了多少次</strong></p>
<p>idf由词在各个文档中数目来决定</p>
<p>N=10，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">df_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>=8，表示总共有十篇文章，单词在8篇文档中出现，idf值为</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mi>d</mi><msub><mi>f</mi><mi>t</mi></msub><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mi>N</mi><mrow><mi>d</mi><msub><mi>f</mi><mi>t</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">idf_t = log\frac{N}{df_t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3534389999999998em;vertical-align:-0.481108em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:-0.10764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mi>F</mi><mo>−</mo><mi>I</mi><mi>D</mi><mi>F</mi><mo>=</mo><mi>t</mi><mi>f</mi><mo>∗</mo><mi>i</mi><mi>d</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">TF-IDF = tf * idf</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span></p>
<h4 id="文本分布式表示"><a class="markdownIt-Anchor" href="#文本分布式表示"></a> 文本分布式表示</h4>
<p>向量空间模型没有体现语义上的接近。”喜欢“和”喜爱“意思接近，但是向量空间模型编码为完全独立的单词。</p>
<p>文本分布式表示又称为“词向量“，将一个词表现为低维、稠密的向量，使得语义上相近的词的词向量也相近（向量之间的距离小）</p>
<p>得到词向量的技术大致有 基于计数和基于预测</p>
<h5 id="基于计数"><a class="markdownIt-Anchor" href="#基于计数"></a> 基于计数</h5>
<h5 id="基于预测"><a class="markdownIt-Anchor" href="#基于预测"></a> 基于预测</h5>
<p>基于预测的文本分布式表示预测什么呢？它的工作是给定前n个词预测第n+1个词是什么词。</p>
<p>第n+1个词会是什么词呢，它有m中可能（m为所有词的个数）。所以我们可以把这个问题看成机器学习中的多分类问题，类别个数为m，输出的是第n+1个词属于每个词的概率</p>
<h1 id="机器学习分类器"><a class="markdownIt-Anchor" href="#机器学习分类器"></a> 机器学习分类器</h1>
<ol>
<li>朴素贝叶斯算法</li>
<li>向量机</li>
<li>k近邻</li>
<li>神经网络</li>
<li>线性回归</li>
<li>决策树</li>
</ol>
<h1 id="深度学习分类器"><a class="markdownIt-Anchor" href="#深度学习分类器"></a> 深度学习分类器</h1>
<ol>
<li>FastText</li>
<li>TextCNN</li>
<li>TextRNN</li>
</ol>
<h2 id="cnn"><a class="markdownIt-Anchor" href="#cnn"></a> CNN</h2>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">严轶轩</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.mryan.cool/2021/10/11/NLP%E5%85%A5%E9%97%A8-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">https://www.mryan.cool/2021/10/11/NLP%E5%85%A5%E9%97%A8-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.mryan.cool" target="_blank">Mr言的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></div><div class="post_share"><div class="social-share" data-image="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/frp7ZH.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付宝"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2021/10/14/python%E4%BE%9D%E8%B5%96%E6%A0%91-pipdeptree/"><img class="prev_cover" src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/frp7ZH.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">python依赖树--pipdeptree</div></div></a></div><div class="next-post pull_right"><a href="/2021/10/11/%E6%9C%BA%E5%99%A8%E3%80%82%E8%87%AA%E7%84%B6%E5%8A%9B%E4%B8%8E%E7%A7%91%E5%AD%A6%E7%9A%84%E5%BA%94%E7%94%A8/"><img class="next_cover" src="https://mryanhehe-1300112970.cos.ap-chengdu.myqcloud.com/uPic/ivw0X8.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">机器。自然力与科学的应用</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 严轶轩</div><div class="framework-info"><span>驱动 </span><a target="_blank" rel="noopener" href="https://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a><span class="footer-separator">|</span><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/"><span>鄂ICP备20008765号-1</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script></body></html>